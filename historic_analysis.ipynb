{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected ROIs for 2015: [(109, 214, 323, 386), (117, 210, 323, 386), (665, 228, 243, 385), (65, 754, 343, 192)]\n",
      "Saved statistics for 2015 to historic_data\\2015\\roi_statistics.csv\n",
      "Selected ROIs for 2016: [(159, 139, 291, 438), (740, 183, 184, 398), (528, 745, 357, 184), (173, 692, 182, 259)]\n",
      "Saved statistics for 2016 to historic_data\\2016\\roi_statistics.csv\n",
      "No HDF files found in historic_data\\2017\n",
      "Skipping historic_data\\2018: Directory not found\n",
      "Skipping historic_data\\2019: Directory not found\n",
      "Skipping historic_data\\2020: Directory not found\n",
      "Skipping historic_data\\2021: Directory not found\n",
      "Skipping historic_data\\2022: Directory not found\n",
      "Skipping historic_data\\2023: Directory not found\n",
      "Skipping historic_data\\2024: Directory not found\n",
      "Skipping historic_data\\2025: Directory not found\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib backend properly\n",
    "plt.switch_backend('TkAgg')  # Try different backend if needed\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=2, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-close after 4 selections\n",
    "        if len(self.rois) >= 4:\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def select_rois(self, background, title):\n",
    "        \"\"\"Interactive ROI selection with proper figure management.\"\"\"\n",
    "        self.rois = []\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 10))\n",
    "        self.ax.imshow(background, cmap='gray')\n",
    "        self.ax.set_title(f\"{title}\\nSelect 4 ROIs (click & drag)\\nClose window when done\")\n",
    "        \n",
    "        rs = RectangleSelector(self.ax, self.on_select,\n",
    "                              useblit=True,\n",
    "                              button=[1],\n",
    "                              minspanx=5, minspany=5,\n",
    "                              spancoords='pixels',\n",
    "                              interactive=True)\n",
    "        \n",
    "        plt.show(block=True)  # Critical for proper interaction\n",
    "        return self.rois\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update to your dataset name\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files for a specific year.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir}: Directory not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    if not hdf_files:\n",
    "        print(f\"No HDF files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Find first valid file for ROI selection\n",
    "    selector = ROISelector()\n",
    "    rois = []\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is not None:\n",
    "            try:\n",
    "                rois = selector.select_rois(background, \n",
    "                                           f\"First valid image for {year}: {file_name}\")\n",
    "                if len(rois) != 4:\n",
    "                    print(f\"Warning: Selected {len(rois)} ROIs instead of 4. Using first 4.\")\n",
    "                    rois = rois[:4]\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"ROI selection failed: {str(e)}\")\n",
    "                return\n",
    "    else:\n",
    "        print(f\"No valid files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Selected ROIs for {year}: {rois}\")\n",
    "    \n",
    "    # Process all files with selected ROIs\n",
    "    stats_list = []\n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is None:\n",
    "            continue\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.imshow(background, cmap='gray')\n",
    "        ax.set_title(f'Background: {file_name} ({year})')\n",
    "        \n",
    "        file_stats = []\n",
    "        for roi_idx, (x, y, w, h) in enumerate(rois):\n",
    "            # Draw rectangle\n",
    "            rect = plt.Rectangle((x, y), w, h,\n",
    "                                linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            roi_data = background[y:y+h, x:x+w]\n",
    "            mean = np.mean(roi_data)\n",
    "            std = np.std(roi_data)\n",
    "            \n",
    "            # Add annotation\n",
    "            ax.text(x, y-10, f'ROI {roi_idx+1}: μ={mean:.2f}, σ={std:.2f}',\n",
    "                    color='red', fontsize=8, backgroundcolor='white')\n",
    "            \n",
    "            file_stats.append({\n",
    "                'Year': year,\n",
    "                'File': file_name,\n",
    "                'ROI': roi_idx+1,\n",
    "                'Mean': mean,\n",
    "                'Std': std\n",
    "            })\n",
    "        \n",
    "        # Save plot\n",
    "        plot_dir = os.path.join(year_dir, 'plots')\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        plot_path = os.path.join(plot_dir, f'{os.path.splitext(file_name)[0]}_plot.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        \n",
    "        stats_list.extend(file_stats)\n",
    "    \n",
    "    # Save statistics\n",
    "    if stats_list:\n",
    "        df = pd.DataFrame(stats_list)\n",
    "        csv_path = os.path.join(year_dir, 'roi_statistics.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved statistics for {year} to {csv_path}\")\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing year 2015 with ROIs at:\n",
      "ROI 1: X=61-478, Y=80-246\n",
      "ROI 2: X=58-454, Y=706-1004\n",
      "ROI 3: X=577-1004, Y=46-550\n",
      "ROI 4: X=566-1004, Y=640-999\n",
      "========================================\n",
      "\n",
      "\n",
      "Year 2015 - File: EPWROSS_2w_527cw_150um.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 656.6950\n",
      "    Standard Deviation: 23.6948\n",
      "    Value Range: 618.00 - 2650.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 658.5005\n",
      "    Standard Deviation: 21.0857\n",
      "    Value Range: 617.00 - 2681.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 660.7198\n",
      "    Standard Deviation: 29.8071\n",
      "    Value Range: 614.00 - 5803.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 662.0486\n",
      "    Standard Deviation: 25.6554\n",
      "    Value Range: 618.00 - 3559.00\n",
      "\n",
      "Year 2015 - File: EPW_2wFiber_200umPH_CCD.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 603.6989\n",
      "    Standard Deviation: 5.7911\n",
      "    Value Range: 533.00 - 649.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 605.6432\n",
      "    Standard Deviation: 5.8730\n",
      "    Value Range: 534.00 - 654.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 603.9088\n",
      "    Standard Deviation: 5.8106\n",
      "    Value Range: 525.00 - 662.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 605.2995\n",
      "    Standard Deviation: 5.8547\n",
      "    Value Range: 525.00 - 652.00\n",
      "\n",
      "Year 2015 - File: IAWROSS_2w_532cw_150um.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 629.7547\n",
      "    Standard Deviation: 27.7013\n",
      "    Value Range: 588.00 - 2963.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 632.7722\n",
      "    Standard Deviation: 31.8713\n",
      "    Value Range: 591.00 - 5951.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 635.6915\n",
      "    Standard Deviation: 26.9680\n",
      "    Value Range: 587.00 - 4383.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 638.2147\n",
      "    Standard Deviation: 31.4011\n",
      "    Value Range: 590.00 - 5439.00\n",
      "\n",
      "Year 2015 - File: IAW_2wFiber_200umPH_CCD.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 605.7083\n",
      "    Standard Deviation: 6.1545\n",
      "    Value Range: 574.00 - 667.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 605.8840\n",
      "    Standard Deviation: 6.1228\n",
      "    Value Range: 575.00 - 634.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 605.5857\n",
      "    Standard Deviation: 6.1353\n",
      "    Value Range: 573.00 - 644.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 605.9536\n",
      "    Standard Deviation: 6.2056\n",
      "    Value Range: 569.00 - 645.00\n",
      "\n",
      "========================================\n",
      "Processing year 2016 with ROIs at:\n",
      "ROI 1: X=41-444, Y=40-394\n",
      "ROI 2: X=633-998, Y=603-992\n",
      "ROI 3: X=661-883, Y=96-460\n",
      "ROI 4: X=101-417, Y=621-910\n",
      "========================================\n",
      "\n",
      "\n",
      "Year 2016 - File: EPW_ccd_o_tcc.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 604.0546\n",
      "    Standard Deviation: 5.9193\n",
      "    Value Range: 554.00 - 647.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 605.7839\n",
      "    Standard Deviation: 6.0035\n",
      "    Value Range: 552.00 - 653.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 604.1276\n",
      "    Standard Deviation: 5.9068\n",
      "    Value Range: 549.00 - 652.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 605.9166\n",
      "    Standard Deviation: 5.9995\n",
      "    Value Range: 551.00 - 651.00\n",
      "\n",
      "Year 2016 - File: IAW_ccd_o_tcc.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 605.2563\n",
      "    Standard Deviation: 6.1500\n",
      "    Value Range: 569.00 - 674.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 606.3384\n",
      "    Standard Deviation: 6.1851\n",
      "    Value Range: 567.00 - 648.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 605.3938\n",
      "    Standard Deviation: 6.1538\n",
      "    Value Range: 566.00 - 642.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 606.1948\n",
      "    Standard Deviation: 6.1950\n",
      "    Value Range: 568.00 - 642.00\n",
      "\n",
      "Year 2016 - File: epw_ross_4w_263p25cw.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 726.2104\n",
      "    Standard Deviation: 117.9121\n",
      "    Value Range: 640.00 - 19244.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 738.1018\n",
      "    Standard Deviation: 100.5774\n",
      "    Value Range: 660.00 - 8815.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 732.9693\n",
      "    Standard Deviation: 101.1160\n",
      "    Value Range: 655.00 - 7809.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 730.9507\n",
      "    Standard Deviation: 88.9623\n",
      "    Value Range: 648.00 - 6849.00\n",
      "\n",
      "Year 2016 - File: iaw_ross_4w_263p25cw.hdf\n",
      "  ROI 1:\n",
      "    Mean/Average: 717.2110\n",
      "    Standard Deviation: 115.5615\n",
      "    Value Range: 631.00 - 15681.00\n",
      "  ROI 2:\n",
      "    Mean/Average: 737.4763\n",
      "    Standard Deviation: 112.0457\n",
      "    Value Range: 648.00 - 13285.00\n",
      "  ROI 3:\n",
      "    Mean/Average: 730.5487\n",
      "    Standard Deviation: 109.3081\n",
      "    Value Range: 644.00 - 8048.00\n",
      "  ROI 4:\n",
      "    Mean/Average: 726.3492\n",
      "    Standard Deviation: 98.2139\n",
      "    Value Range: 641.00 - 7949.00\n",
      "No HDF files found in historic_data\\2017\n",
      "Skipping historic_data\\2018: Directory not found\n",
      "Skipping historic_data\\2019: Directory not found\n",
      "Skipping historic_data\\2020: Directory not found\n",
      "Skipping historic_data\\2021: Directory not found\n",
      "Skipping historic_data\\2022: Directory not found\n",
      "Skipping historic_data\\2023: Directory not found\n",
      "Skipping historic_data\\2024: Directory not found\n",
      "Skipping historic_data\\2025: Directory not found\n",
      "\n",
      "Processing completed. All results printed above.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Configure matplotlib backend for interactivity\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=2, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-close after 4 selections\n",
    "        if len(self.rois) >= 4:\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def select_rois(self, background, title):\n",
    "        \"\"\"Interactive ROI selection with proper figure management.\"\"\"\n",
    "        self.rois = []\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 10))\n",
    "        self.ax.imshow(background, cmap='gray')\n",
    "        self.ax.set_title(f\"{title}\\nSelect 4 ROIs (click & drag)\\nClose window when done\")\n",
    "        \n",
    "        rs = RectangleSelector(self.ax, self.on_select,\n",
    "                              useblit=True,\n",
    "                              button=[1],\n",
    "                              minspanx=5, minspany=5,\n",
    "                              spancoords='pixels',\n",
    "                              interactive=True)\n",
    "        \n",
    "        plt.show(block=True)\n",
    "        return self.rois\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update to your dataset name\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files for a specific year.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir}: Directory not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    if not hdf_files:\n",
    "        print(f\"No HDF files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    # ROI Selection\n",
    "    selector = ROISelector()\n",
    "    rois = []\n",
    "    \n",
    "    # Find first valid file for ROI selection\n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is not None:\n",
    "            try:\n",
    "                rois = selector.select_rois(background, f\"First valid image for {year}: {file_name}\")\n",
    "                if len(rois) != 4:\n",
    "                    print(f\"Selected {len(rois)} ROIs. Using first 4.\")\n",
    "                    rois = rois[:4]\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"ROI selection failed: {str(e)}\")\n",
    "                return\n",
    "    else:\n",
    "        print(f\"No valid files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing year {year} with ROIs at:\")\n",
    "    for idx, (x, y, w, h) in enumerate(rois):\n",
    "        print(f\"ROI {idx+1}: X={x}-{x+w}, Y={y}-{y+h}\")\n",
    "    print(f\"{'='*40}\\n\")\n",
    "    \n",
    "    # Process all files\n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is None:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nYear {year} - File: {file_name}\")\n",
    "        for roi_idx, (x, y, w, h) in enumerate(rois):\n",
    "            roi_data = background[y:y+h, x:x+w]\n",
    "            mean = np.mean(roi_data)\n",
    "            std = np.std(roi_data)\n",
    "            \n",
    "            print(f\"  ROI {roi_idx+1}:\")\n",
    "            print(f\"    Mean/Average: {mean:.4f}\")\n",
    "            print(f\"    Standard Deviation: {std:.4f}\")\n",
    "            print(f\"    Value Range: {np.min(roi_data):.2f} - {np.max(roi_data):.2f}\")\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "print(\"\\nProcessing completed. All results printed above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year 2015 - File: EPWROSS_2w_527cw_150um.hdf\n",
      "  ROI 1:\n",
      "    Mean: 657.3184\n",
      "    Std Dev: 21.1244\n",
      "  ROI 2:\n",
      "    Mean: 660.7423\n",
      "    Std Dev: 25.2478\n",
      "\n",
      "Year 2015 - File: EPW_2wFiber_200umPH_CCD.hdf\n",
      "  ROI 1:\n",
      "    Mean: 604.4100\n",
      "    Std Dev: 5.8834\n",
      "  ROI 2:\n",
      "    Mean: 604.4996\n",
      "    Std Dev: 5.8544\n",
      "\n",
      "Year 2015 - File: IAWROSS_2w_532cw_150um.hdf\n",
      "  ROI 1:\n",
      "    Mean: 631.1819\n",
      "    Std Dev: 26.6383\n",
      "  ROI 2:\n",
      "    Mean: 636.2883\n",
      "    Std Dev: 30.1290\n",
      "\n",
      "Year 2015 - File: IAW_2wFiber_200umPH_CCD.hdf\n",
      "  ROI 1:\n",
      "    Mean: 605.6520\n",
      "    Std Dev: 6.1153\n",
      "  ROI 2:\n",
      "    Mean: 605.7463\n",
      "    Std Dev: 6.2014\n",
      "Selected 0 ROIs. Using first 2.\n",
      "\n",
      "Year 2016 - File: EPW_ccd_o_tcc.hdf\n",
      "\n",
      "Year 2016 - File: IAW_ccd_o_tcc.hdf\n",
      "\n",
      "Year 2016 - File: epw_ross_4w_263p25cw.hdf\n",
      "\n",
      "Year 2016 - File: iaw_ross_4w_263p25cw.hdf\n",
      "No HDF files found in historic_data\\2017\n",
      "Skipping historic_data\\2018: Directory not found\n",
      "Skipping historic_data\\2019: Directory not found\n",
      "Skipping historic_data\\2020: Directory not found\n",
      "Skipping historic_data\\2021: Directory not found\n",
      "Skipping historic_data\\2022: Directory not found\n",
      "Skipping historic_data\\2023: Directory not found\n",
      "Skipping historic_data\\2024: Directory not found\n",
      "Skipping historic_data\\2025: Directory not found\n",
      "\n",
      "Processing completed. All histograms displayed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Configure matplotlib backend for interactivity\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=2, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-close after 2 selections\n",
    "        if len(self.rois) >= 2:\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def select_rois(self, background, title):\n",
    "        \"\"\"Interactive ROI selection with proper figure management.\"\"\"\n",
    "        self.rois = []\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 10))\n",
    "        self.ax.imshow(background, cmap='gray')\n",
    "        self.ax.set_title(f\"{title}\\nSelect 2 ROIs (click & drag)\\nClose window when done\")\n",
    "        \n",
    "        rs = RectangleSelector(self.ax, self.on_select,\n",
    "                              useblit=True,\n",
    "                              button=[1],\n",
    "                              minspanx=5, minspany=5,\n",
    "                              spancoords='pixels',\n",
    "                              interactive=True)\n",
    "        \n",
    "        plt.show(block=True)\n",
    "        return self.rois\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update to your dataset name\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files for a specific year.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir}: Directory not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    if not hdf_files:\n",
    "        print(f\"No HDF files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    # ROI Selection\n",
    "    selector = ROISelector()\n",
    "    rois = []\n",
    "    \n",
    "    # Find first valid file for ROI selection\n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is not None:\n",
    "            try:\n",
    "                rois = selector.select_rois(background, f\"First valid image for {year}: {file_name}\")\n",
    "                if len(rois) != 2:\n",
    "                    print(f\"Selected {len(rois)} ROIs. Using first 2.\")\n",
    "                    rois = rois[:2]\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"ROI selection failed: {str(e)}\")\n",
    "                return\n",
    "    else:\n",
    "        print(f\"No valid files found in {year_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Process all files\n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        background = process_hdf4(file_path)\n",
    "        if background is None:\n",
    "            continue\n",
    "        \n",
    "        # Collect all pixel values from all ROIs\n",
    "        all_pixels = []\n",
    "        stats = []\n",
    "        \n",
    "        print(f\"\\nYear {year} - File: {file_name}\")\n",
    "        for roi_idx, (x, y, w, h) in enumerate(rois):\n",
    "            try:\n",
    "                roi_data = background[y:y+h, x:x+w]\n",
    "                all_pixels.extend(roi_data.flatten())\n",
    "                \n",
    "                # Calculate statistics\n",
    "                mean = np.mean(roi_data)\n",
    "                std = np.std(roi_data)\n",
    "                stats.append((mean, std))\n",
    "                \n",
    "                print(f\"  ROI {roi_idx+1}:\")\n",
    "                print(f\"    Mean: {mean:.4f}\")\n",
    "                print(f\"    Std Dev: {std:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing ROI {roi_idx+1}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create combined histogram\n",
    "        if all_pixels:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(all_pixels, bins=50, color='blue', alpha=0.7,\n",
    "                    edgecolor='black', density=False)\n",
    "            plt.title(f\"Pixel Value Distribution\\n{file_name} ({year})\")\n",
    "            plt.xlabel(\"Pixel Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics to plot\n",
    "            stats_text = \"\\n\".join([f\"ROI {i+1}: μ={m:.2f} σ={s:.2f}\" \n",
    "                                  for i, (m, s) in enumerate(stats)])\n",
    "            plt.annotate(stats_text, xy=(0.98, 0.98), xycoords='axes fraction',\n",
    "                        ha='right', va='top', fontsize=9,\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "print(\"\\nProcessing completed. All histograms displayed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed: EPWROSS_2w_527cw_150um.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: EPW_2wFiber_200umPH_CCD.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: IAWROSS_2w_532cw_150um.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: IAW_2wFiber_200umPH_CCD.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: EPW_ccd_o_tcc.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: IAW_ccd_o_tcc.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: epw_ross_4w_263p25cw.hdf\n",
      "Total pixels analyzed: 0\n",
      "\n",
      "Processed: iaw_ross_4w_263p25cw.hdf\n",
      "Total pixels analyzed: 0\n",
      "Skipping historic_data\\2018 - not found\n",
      "Skipping historic_data\\2019 - not found\n",
      "Skipping historic_data\\2020 - not found\n",
      "Skipping historic_data\\2021 - not found\n",
      "Skipping historic_data\\2022 - not found\n",
      "Skipping historic_data\\2023 - not found\n",
      "Skipping historic_data\\2024 - not found\n",
      "Skipping historic_data\\2025 - not found\n",
      "\n",
      "Processing completed. All files analyzed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        if len(self.rois) >= 4:\n",
    "            return\n",
    "        \n",
    "        # Get coordinates\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-process when 4 ROIs are selected\n",
    "        if len(self.rois) == 4:\n",
    "            self.process_rois()\n",
    "\n",
    "    def process_rois(self):\n",
    "        \"\"\"Calculate statistics and update histogram.\"\"\"\n",
    "        # Collect all pixel values\n",
    "        all_pixels = []\n",
    "        stats = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                pixels = roi_data.flatten()\n",
    "                all_pixels.extend(pixels)\n",
    "                stats.append((np.mean(pixels), np.std(pixels)))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ROI: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Update histogram\n",
    "        self.ax_hist.clear()\n",
    "        if all_pixels:\n",
    "            self.ax_hist.hist(all_pixels, bins=50, color='blue', \n",
    "                            alpha=0.7, edgecolor='black')\n",
    "            self.ax_hist.set_title(\"Pixel Value Distribution\")\n",
    "            self.ax_hist.set_xlabel(\"Pixel Value\")\n",
    "            self.ax_hist.set_ylabel(\"Frequency\")\n",
    "            self.ax_hist.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            stats_text = \"\\n\".join(\n",
    "                [f\"ROI {i+1}: μ={m:.2f} σ={s:.2f}\" \n",
    "                 for i, (m, s) in enumerate(stats)]\n",
    "            )\n",
    "            self.ax_hist.text(0.98, 0.98, stats_text,\n",
    "                            transform=self.ax_hist.transAxes,\n",
    "                            ha='right', va='top',\n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "            \n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update dataset name\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    \"\"\"Analyze a single file with combined interface.\"\"\"\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    # Image subplot\n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 4 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    # Histogram subplot\n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.set_title(\"Histogram will update after 4 ROI selections\")\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    # Add ROI selector\n",
    "    rs = RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                          useblit=True,\n",
    "                          button=[1],\n",
    "                          minspanx=5, minspany=5,\n",
    "                          spancoords='pixels',\n",
    "                          interactive=True)\n",
    "    \n",
    "    # Add instructions\n",
    "    analyzer.fig.text(0.5, 0.02, \n",
    "                    \"Select 4 ROIs by click-and-drag | Close window to continue\",\n",
    "                    ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nProcessed: {os.path.basename(file_path)}\")\n",
    "    print(f\"Total pixels analyzed: {sum([w*h for x,y,w,h in analyzer.rois])}\")\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files in a year directory.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir} - not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        analyze_file(file_path, year)\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "print(\"\\nProcessing completed. All files analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed: EPWROSS_2w_527cw_150um.hdf\n",
      "Combined Statistics:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 159\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2026\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mprocess_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing completed. All files analyzed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 155\u001b[0m, in \u001b[0;36mprocess_year\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m hdf_files:\n\u001b[0;32m    154\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(year_dir, file_name)\n\u001b[1;32m--> 155\u001b[0m     \u001b[43manalyze_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 139\u001b[0m, in \u001b[0;36manalyze_file\u001b[1;34m(file_path, year)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalyzer\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Median: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalyzer\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Std Dev: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalyzer\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        self.stats = {}\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        # Get coordinates\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-process when 2 ROIs are selected\n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "\n",
    "    def process_rois(self):\n",
    "        \"\"\"Calculate statistics and update histogram.\"\"\"\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ROI: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate combined statistics\n",
    "        if combined_pixels:\n",
    "            stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Update histogram\n",
    "            self.ax_hist.clear()\n",
    "            n, bins, patches = self.ax_hist.hist(combined_pixels, bins=50, \n",
    "                                                color='blue', alpha=0.7, \n",
    "                                                edgecolor='black')\n",
    "            \n",
    "            # Add statistics annotation\n",
    "            stats_text = (f\"Combined Statistics:\\n\"\n",
    "                         f\"Mean: {stats['mean']:.2f}\\n\"\n",
    "                         f\"Median: {stats['median']:.2f}\\n\"\n",
    "                         f\"Std Dev: {stats['std']:.2f}\\n\"\n",
    "                         f\"Total Pixels: {len(combined_pixels):,}\")\n",
    "            \n",
    "            self.ax_hist.text(0.98, 0.98, stats_text,\n",
    "                            transform=self.ax_hist.transAxes,\n",
    "                            ha='right', va='top',\n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "            \n",
    "            self.ax_hist.set_title(\"Combined Pixel Distribution\")\n",
    "            self.ax_hist.set_xlabel(\"Pixel Value\")\n",
    "            self.ax_hist.set_ylabel(\"Frequency\")\n",
    "            self.ax_hist.grid(True, alpha=0.3)\n",
    "            \n",
    "            self.fig.canvas.draw()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update dataset name if needed\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    \"\"\"Analyze a single file with combined interface.\"\"\"\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    # Image subplot\n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    # Histogram subplot\n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.set_title(\"Histogram will update after 2 ROI selections\")\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    # Add ROI selector\n",
    "    rs = RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                          useblit=True,\n",
    "                          button=[1],\n",
    "                          minspanx=5, minspany=5,\n",
    "                          spancoords='pixels',\n",
    "                          interactive=True)\n",
    "    \n",
    "    # Add instructions\n",
    "    analyzer.fig.text(0.5, 0.02, \n",
    "                    \"Select 2 ROIs by click-and-drag | Close window to continue\",\n",
    "                    ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nProcessed: {os.path.basename(file_path)}\")\n",
    "    print(f\"Combined Statistics:\")\n",
    "    print(f\"- Mean: {analyzer.stats.get('mean', 'N/A'):.2f}\")\n",
    "    print(f\"- Median: {analyzer.stats.get('median', 'N/A'):.2f}\")\n",
    "    print(f\"- Std Dev: {analyzer.stats.get('std', 'N/A'):.2f}\")\n",
    "    print(f\"- Total Pixels: {analyzer.stats.get('total_pixels', 'N/A'):,}\")\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files in a year directory.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir} - not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        analyze_file(file_path, year)\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "print(\"\\nProcessing completed. All files analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed: EPWROSS_2w_527cw_150um.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 660.18\n",
      "- Median: 657.00\n",
      "- Std Dev: 26.94\n",
      "- Total Pixels: 518,379\n",
      "\n",
      "Processed: EPW_2wFiber_200umPH_CCD.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 604.26\n",
      "- Median: 604.00\n",
      "- Std Dev: 5.86\n",
      "- Total Pixels: 489,657\n",
      "\n",
      "Processed: IAWROSS_2w_532cw_150um.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 634.83\n",
      "- Median: 629.00\n",
      "- Std Dev: 37.65\n",
      "- Total Pixels: 506,520\n",
      "\n",
      "Processed: IAW_2wFiber_200umPH_CCD.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 605.73\n",
      "- Median: 606.00\n",
      "- Std Dev: 6.16\n",
      "- Total Pixels: 516,310\n",
      "\n",
      "Processed: EPW_ccd_o_tcc.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 604.85\n",
      "- Median: 605.00\n",
      "- Std Dev: 5.99\n",
      "- Total Pixels: 365,292\n",
      "\n",
      "Processed: IAW_ccd_o_tcc.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 605.58\n",
      "- Median: 606.00\n",
      "- Std Dev: 6.17\n",
      "- Total Pixels: 454,181\n",
      "\n",
      "Processed: epw_ross_4w_263p25cw.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 738.07\n",
      "- Median: 717.00\n",
      "- Std Dev: 124.69\n",
      "- Total Pixels: 564,112\n",
      "\n",
      "Processed: iaw_ross_4w_263p25cw.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 724.09\n",
      "- Median: 704.00\n",
      "- Std Dev: 110.55\n",
      "- Total Pixels: 172,719\n",
      "Skipping historic_data\\2018 - not found\n",
      "Skipping historic_data\\2019 - not found\n",
      "Skipping historic_data\\2020 - not found\n",
      "Skipping historic_data\\2021 - not found\n",
      "Skipping historic_data\\2022 - not found\n",
      "Skipping historic_data\\2023 - not found\n",
      "Skipping historic_data\\2024 - not found\n",
      "Skipping historic_data\\2025 - not found\n",
      "\n",
      "Processed: EPWROSS_2w_527cw_150um.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 658.63\n",
      "- Median: 656.00\n",
      "- Std Dev: 24.89\n",
      "- Total Pixels: 363,222\n",
      "\n",
      "Processed: EPW_2wFiber_200umPH_CCD.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 604.01\n",
      "- Median: 604.00\n",
      "- Std Dev: 5.81\n",
      "- Total Pixels: 276,966\n",
      "\n",
      "Processed: IAWROSS_2w_532cw_150um.hdf\n",
      "Combined Statistics:\n",
      "- Mean: 634.40\n",
      "- Median: 631.00\n",
      "- Std Dev: 28.16\n",
      "- Total Pixels: 419,191\n",
      "\n",
      "Processed: IAW_2wFiber_200umPH_CCD.hdf\n",
      "No valid statistics calculated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 170\u001b[0m\n\u001b[0;32m    168\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2026\u001b[39m):\n\u001b[1;32m--> 170\u001b[0m     year_result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m year_result:\n\u001b[0;32m    172\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(year_result)\n",
      "Cell \u001b[1;32mIn[4], line 161\u001b[0m, in \u001b[0;36mprocess_year\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m hdf_files:\n\u001b[0;32m    160\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(year_dir, file_name)\n\u001b[1;32m--> 161\u001b[0m     \u001b[43manalyze_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 137\u001b[0m, in \u001b[0;36manalyze_file\u001b[1;34m(file_path, year)\u001b[0m\n\u001b[0;32m    132\u001b[0m analyzer\u001b[38;5;241m.\u001b[39mfig\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.02\u001b[39m, \n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect 2 ROIs by click-and-drag | Close window to continue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m                 ha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    136\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m--> 137\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Print statistics after processing\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backend_bases.py:3553\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3553\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:520\u001b[0m, in \u001b[0;36mFigureManagerTk.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    518\u001b[0m manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     \u001b[43mfirst_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        self.stats = {}  # Initialize stats dictionary\n",
    "        \n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        # Get coordinates\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        # Auto-process when 2 ROIs are selected\n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "\n",
    "    def process_rois(self):\n",
    "        \"\"\"Calculate statistics and update histogram.\"\"\"\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ROI: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate combined statistics\n",
    "        self.stats = {}  # Reset stats\n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total_pixels': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Update histogram\n",
    "            self.ax_hist.clear()\n",
    "            n, bins, patches = self.ax_hist.hist(combined_pixels, bins=50, \n",
    "                                                color='blue', alpha=0.7, \n",
    "                                                edgecolor='black')\n",
    "            \n",
    "            # Add statistics annotation\n",
    "            stats_text = (f\"Combined Statistics:\\n\"\n",
    "                         f\"Mean: {self.stats['mean']:.2f}\\n\"\n",
    "                         f\"Median: {self.stats['median']:.2f}\\n\"\n",
    "                         f\"Std Dev: {self.stats['std']:.2f}\\n\"\n",
    "                         f\"Total Pixels: {self.stats['total_pixels']:,}\")\n",
    "            \n",
    "            self.ax_hist.text(0.98, 0.98, stats_text,\n",
    "                            transform=self.ax_hist.transAxes,\n",
    "                            ha='right', va='top',\n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "            \n",
    "            self.ax_hist.set_title(\"Combined Pixel Distribution\")\n",
    "            self.ax_hist.set_xlabel(\"Pixel Value\")\n",
    "            self.ax_hist.set_ylabel(\"Frequency\")\n",
    "            self.ax_hist.grid(True, alpha=0.3)\n",
    "            \n",
    "            self.fig.canvas.draw()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and extract background image.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Update dataset name if needed\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    \"\"\"Analyze a single file with combined interface.\"\"\"\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    # Image subplot\n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    # Histogram subplot\n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.set_title(\"Histogram will update after 2 ROI selections\")\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    # Add ROI selector\n",
    "    rs = RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                          useblit=True,\n",
    "                          button=[1],\n",
    "                          minspanx=5, minspany=5,\n",
    "                          spancoords='pixels',\n",
    "                          interactive=True)\n",
    "    \n",
    "    # Add instructions\n",
    "    analyzer.fig.text(0.5, 0.02, \n",
    "                    \"Select 2 ROIs by click-and-drag | Close window to continue\",\n",
    "                    ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics after processing\n",
    "    print(f\"\\nProcessed: {os.path.basename(file_path)}\")\n",
    "    if analyzer.stats:\n",
    "        print(f\"Combined Statistics:\")\n",
    "        print(f\"- Mean: {analyzer.stats.get('mean', 'N/A'):.2f}\")\n",
    "        print(f\"- Median: {analyzer.stats.get('median', 'N/A'):.2f}\")\n",
    "        print(f\"- Std Dev: {analyzer.stats.get('std', 'N/A'):.2f}\")\n",
    "        print(f\"- Total Pixels: {analyzer.stats.get('total_pixels', 'N/A'):,}\")\n",
    "    else:\n",
    "        print(\"No valid statistics calculated\")\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files in a year directory.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Skipping {year_dir} - not found\")\n",
    "        return\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        analyze_file(file_path, year)\n",
    "\n",
    "# Main execution\n",
    "for year in range(2015, 2026):\n",
    "    process_year(year)\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create CSV structure\n",
    "if all_data:\n",
    "    # Collect all unique filenames\n",
    "    filenames = set()\n",
    "    for entry in all_data:\n",
    "        filenames.update(entry.keys() - {'Year'})\n",
    "    sorted_files = sorted(filenames)\n",
    "    \n",
    "    # Create column headers\n",
    "    columns = ['Year']\n",
    "    for fname in sorted_files:\n",
    "        columns.extend([\n",
    "            f\"{fname}_mean\",\n",
    "            f\"{fname}_median\",\n",
    "            f\"{fname}_std\",\n",
    "            f\"{fname}_total\"\n",
    "        ])\n",
    "    \n",
    "    # Build CSV rows\n",
    "    csv_rows = []\n",
    "    for entry in all_data:\n",
    "        row = [entry['Year']]\n",
    "        for fname in sorted_files:\n",
    "            if fname in entry:\n",
    "                stats = entry[fname]\n",
    "                row.extend([\n",
    "                    stats.get('mean', np.nan),\n",
    "                    stats.get('median', np.nan),\n",
    "                    stats.get('std', np.nan),\n",
    "                    stats.get('total', np.nan)\n",
    "                ])\n",
    "            else:\n",
    "                row.extend([np.nan]*4)\n",
    "        csv_rows.append(row)\n",
    "    \n",
    "    # Create and save DataFrame\n",
    "    df = pd.DataFrame(csv_rows, columns=columns)\n",
    "    df.to_csv('analysis_results.csv', index=False)\n",
    "    print(\"Results saved to analysis_results.csv\")\n",
    "else:\n",
    "    print(\"No data processed\")\n",
    "    \n",
    "print(\"\\nProcessing completed. All files analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to analysis_results.csv\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "results = []\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        self.stats = {}\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "\n",
    "    def process_rois(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            self.ax_hist.clear()\n",
    "            self.ax_hist.hist(combined_pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "            \n",
    "            stats_text = (f\"Combined Statistics:\\n\"\n",
    "                         f\"Mean: {self.stats['mean']:.2f}\\n\"\n",
    "                         f\"Median: {self.stats['median']:.2f}\\n\"\n",
    "                         f\"Std Dev: {self.stats['std']:.2f}\\n\"\n",
    "                         f\"Total Pixels: {self.stats['total']:,}\")\n",
    "            \n",
    "            self.ax_hist.text(0.98, 0.98, stats_text,\n",
    "                            transform=self.ax_hist.transAxes,\n",
    "                            ha='right', va='top',\n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "            \n",
    "            self.ax_hist.set_title(\"Combined Pixel Distribution\")\n",
    "            self.ax_hist.set_xlabel(\"Pixel Value\")\n",
    "            self.ax_hist.set_ylabel(\"Frequency\")\n",
    "            self.ax_hist.grid(True, alpha=0.3)\n",
    "            \n",
    "            self.fig.canvas.draw()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                     useblit=True, button=[1],\n",
    "                     minspanx=5, minspany=5,\n",
    "                     spancoords='pixels', interactive=True)\n",
    "    \n",
    "    analyzer.fig.text(0.5, 0.02, \n",
    "                     \"Select 2 ROIs by click-and-drag | Close window to continue\",\n",
    "                     ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return os.path.basename(file_path), analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        if filename and stats:\n",
    "            year_data[filename] = stats\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create CSV structure\n",
    "if all_data:\n",
    "    # Collect all unique filenames\n",
    "    filenames = set()\n",
    "    for entry in all_data:\n",
    "        filenames.update(entry.keys() - {'Year'})\n",
    "    sorted_files = sorted(filenames)\n",
    "    \n",
    "    # Create column headers\n",
    "    columns = ['Year']\n",
    "    for fname in sorted_files:\n",
    "        columns.extend([\n",
    "            f\"{fname}_mean\",\n",
    "            f\"{fname}_median\",\n",
    "            f\"{fname}_std\",\n",
    "            f\"{fname}_total\"\n",
    "        ])\n",
    "    \n",
    "    # Build CSV rows\n",
    "    csv_rows = []\n",
    "    for entry in all_data:\n",
    "        row = [entry['Year']]\n",
    "        for fname in sorted_files:\n",
    "            if fname in entry:\n",
    "                stats = entry[fname]\n",
    "                row.extend([\n",
    "                    stats.get('mean', np.nan),\n",
    "                    stats.get('median', np.nan),\n",
    "                    stats.get('std', np.nan),\n",
    "                    stats.get('total', np.nan)\n",
    "                ])\n",
    "            else:\n",
    "                row.extend([np.nan]*4)\n",
    "        csv_rows.append(row)\n",
    "    \n",
    "    # Create and save DataFrame\n",
    "    df = pd.DataFrame(csv_rows, columns=columns)\n",
    "    df.to_csv('analysis_results.csv', index=False)\n",
    "    print(\"Results saved to analysis_results.csv\")\n",
    "else:\n",
    "    print(\"No data processed\")\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to analysis_results.csv\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "plt.switch_backend('TkAgg')  # Force interactive backend\n",
    "base_dir = 'historic_data'\n",
    "results = []\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        self.stats = {}\n",
    "        self.selection_complete = False\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        # Get coordinates\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "            self.selection_complete = True\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def process_rois(self):\n",
    "        \"\"\"Calculate statistics and update histogram.\"\"\"\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    # Image subplot\n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    # Histogram subplot\n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    # Add ROI selector\n",
    "    rs = RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                          useblit=True,\n",
    "                          button=[1],\n",
    "                          minspanx=5, minspany=5,\n",
    "                          spancoords='pixels',\n",
    "                          interactive=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)  # Block until window closes\n",
    "    \n",
    "    return os.path.basename(file_path), analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        if filename and stats:\n",
    "            year_data[f\"{filename}_mean\"] = stats['mean']\n",
    "            year_data[f\"{filename}_median\"] = stats['median']\n",
    "            year_data[f\"{filename}_std\"] = stats['std']\n",
    "            year_data[f\"{filename}_total\"] = stats['total']\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create and save DataFrame\n",
    "if all_data:\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Reorder columns: Year first, then alphabetical files with metrics\n",
    "    columns = ['Year'] + sorted([c for c in df.columns if c != 'Year'])\n",
    "    df = df[columns]\n",
    "    \n",
    "    df.to_csv('analysis_results.csv', index=False)\n",
    "    print(\"Results saved to analysis_results.csv\")\n",
    "else:\n",
    "    print(\"No data processed\")\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to categorized_results.csv\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "# Category mapping function\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.ax_hist = None\n",
    "        self.stats = {}\n",
    "        self.selection_complete = False\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax_image.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "            self.selection_complete = True\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def process_rois(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('ImageData')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    analyzer.fig = plt.figure(figsize=(14, 6))\n",
    "    gs = analyzer.fig.add_gridspec(1, 2, width_ratios=[1.2, 1])\n",
    "    \n",
    "    analyzer.ax_image = analyzer.fig.add_subplot(gs[0])\n",
    "    analyzer.ax_image.imshow(background, cmap='gray')\n",
    "    analyzer.ax_image.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    analyzer.ax_hist = analyzer.fig.add_subplot(gs[1])\n",
    "    analyzer.ax_hist.axis('off')\n",
    "    \n",
    "    RectangleSelector(analyzer.ax_image, analyzer.on_select,\n",
    "                    useblit=True, button=[1],\n",
    "                    minspanx=5, minspany=5,\n",
    "                    spancoords='pixels', interactive=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)\n",
    "    \n",
    "    return os.path.basename(file_path), analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    \n",
    "    # Initialize category storage\n",
    "    categories = {\n",
    "        'iaw ccd': {'means': [], 'medians': [], 'stds': [], 'totals': []},\n",
    "        'iaw ross': {'means': [], 'medians': [], 'stds': [], 'totals': []},\n",
    "        'epw ccd': {'means': [], 'medians': [], 'stds': [], 'totals': []},\n",
    "        'epw ross': {'means': [], 'medians': [], 'stds': [], 'totals': []}\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        \n",
    "        if filename and stats:\n",
    "            category = categorize_file(filename)\n",
    "            if category in categories:\n",
    "                categories[category]['means'].append(stats['mean'])\n",
    "                categories[category]['medians'].append(stats['median'])\n",
    "                categories[category]['stds'].append(stats['std'])\n",
    "                categories[category]['totals'].append(stats['total'])\n",
    "    \n",
    "    # Calculate aggregated statistics for each category\n",
    "    for category, data in categories.items():\n",
    "        if data['means']:\n",
    "            year_data[f\"{category}_mean\"] = np.mean(data['means'])\n",
    "            year_data[f\"{category}_median\"] = np.mean(data['medians'])\n",
    "            year_data[f\"{category}_std\"] = np.mean(data['stds'])\n",
    "            year_data[f\"{category}_total\"] = np.sum(data['totals'])\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create and save DataFrame\n",
    "if all_data:\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Define column order\n",
    "    columns = ['Year']\n",
    "    for category in ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']:\n",
    "        columns += [\n",
    "            f\"{category}_mean\",\n",
    "            f\"{category}_median\", \n",
    "            f\"{category}_std\",\n",
    "            f\"{category}_total\"\n",
    "        ]\n",
    "    \n",
    "    df = df.reindex(columns=columns)\n",
    "    df.to_csv('categorized_results.csv', index=False)\n",
    "    print(\"Results saved to categorized_results.csv\")\n",
    "else:\n",
    "    print(\"No data processed\")\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2015\n",
      "Processing: historic_data\\2015\\EPWROSS_2w_527cw_150um.hdf\n",
      "Processing: historic_data\\2015\\EPW_2wFiber_200umPH_CCD.hdf\n",
      "Processing: historic_data\\2015\\IAWROSS_2w_532cw_150um.hdf\n",
      "Processing: historic_data\\2015\\IAW_2wFiber_200umPH_CCD.hdf\n",
      "\n",
      "Processing year 2016\n",
      "Processing: historic_data\\2016\\EPW_ccd_o_tcc.hdf\n",
      "Processing: historic_data\\2016\\IAW_ccd_o_tcc.hdf\n",
      "Processing: historic_data\\2016\\epw_ross_4w_263p25cw.hdf\n",
      "Processing: historic_data\\2016\\iaw_ross_4w_263p25cw.hdf\n",
      "\n",
      "Processing year 2017\n",
      "\n",
      "Processing year 2018\n",
      "Directory not found: historic_data\\2018\n",
      "\n",
      "Processing year 2019\n",
      "Directory not found: historic_data\\2019\n",
      "\n",
      "Processing year 2020\n",
      "Directory not found: historic_data\\2020\n",
      "\n",
      "Processing year 2021\n",
      "Directory not found: historic_data\\2021\n",
      "\n",
      "Processing year 2022\n",
      "Directory not found: historic_data\\2022\n",
      "\n",
      "Processing year 2023\n",
      "Directory not found: historic_data\\2023\n",
      "\n",
      "Processing year 2024\n",
      "Directory not found: historic_data\\2024\n",
      "\n",
      "Processing year 2025\n",
      "Directory not found: historic_data\\2025\n",
      "\n",
      "Results successfully saved to categorized_results.csv\n",
      "\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "# Category mapping function\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.background = None\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        # Get coordinates\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        plt.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def process_rois(self):\n",
    "        \"\"\"Calculate statistics from selected ROIs.\"\"\"\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ROI: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and verify data structure.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')  # Verify dataset name\n",
    "        data = dataset.get()\n",
    "        \n",
    "        # Verify data shape\n",
    "        if data.shape[0] < 2:\n",
    "            raise ValueError(\"Invalid dataset structure\")\n",
    "            \n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    \"\"\"Analyze a single file with interactive ROI selection.\"\"\"\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    # Create figure\n",
    "    analyzer.fig, analyzer.ax = plt.subplots(figsize=(10, 6))\n",
    "    analyzer.ax.imshow(background, cmap='gray')\n",
    "    analyzer.ax.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    # Connect selector\n",
    "    rs = RectangleSelector(analyzer.ax, analyzer.on_select,\n",
    "                          useblit=True,\n",
    "                          button=[1],\n",
    "                          minspanx=5, minspany=5,\n",
    "                          spancoords='pixels',\n",
    "                          interactive=True)\n",
    "    \n",
    "    # Show plot and block execution\n",
    "    plt.show(block=True)\n",
    "    plt.close()  # Ensure figure is properly closed\n",
    "    \n",
    "    return os.path.basename(file_path), analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    \"\"\"Process all files in a year directory.\"\"\"\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        print(f\"Directory not found: {year_dir}\")\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        print(f\"Processing: {file_path}\")\n",
    "        \n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        if not stats:\n",
    "            continue\n",
    "        \n",
    "        # Categorize file\n",
    "        category = categorize_file(filename)\n",
    "        if category not in category_data:\n",
    "            continue\n",
    "            \n",
    "        # Store stats\n",
    "        category_data[category].append({\n",
    "            'mean': stats['mean'],\n",
    "            'median': stats['median'],\n",
    "            'std': stats['std'],\n",
    "            'total': stats['total']\n",
    "        })\n",
    "    \n",
    "    # Aggregate category data\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_data[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_data[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_data[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_data[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"\\nProcessing year {year}\")\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create and save DataFrame\n",
    "if all_data:\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Ensure column order\n",
    "    columns = ['Year']\n",
    "    for category in ['iaw_ccd', 'iaw_ross', 'epw_ccd', 'epw_ross']:\n",
    "        columns += [f\"{category}_mean\", f\"{category}_median\", \n",
    "                   f\"{category}_std\", f\"{category}_total\"]\n",
    "    \n",
    "    df = df.reindex(columns=columns)\n",
    "    df.to_csv('categorized_results.csv', index=False)\n",
    "    print(\"\\nResults successfully saved to categorized_results.csv\")\n",
    "else:\n",
    "    print(\"\\nNo data processed\")\n",
    "\n",
    "print(\"\\nProcessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2026\u001b[39m):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m     year_stat, year_hists \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m year_stat:\n\u001b[0;32m    167\u001b[0m         all_stats\u001b[38;5;241m.\u001b[39mappend(year_stat)\n",
      "Cell \u001b[1;32mIn[6], line 130\u001b[0m, in \u001b[0;36mprocess_year\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m hdf_files:\n\u001b[0;32m    129\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(year_dir, file_name)\n\u001b[1;32m--> 130\u001b[0m     filename, stats, hist \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stats \u001b[38;5;129;01mand\u001b[39;00m hist:\n\u001b[0;32m    133\u001b[0m         category \u001b[38;5;241m=\u001b[39m categorize_file(filename)\n",
      "Cell \u001b[1;32mIn[6], line 107\u001b[0m, in \u001b[0;36manalyze_file\u001b[1;34m(file_path, year)\u001b[0m\n\u001b[0;32m    100\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect 2 ROIs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m RectangleSelector(ax, analyzer\u001b[38;5;241m.\u001b[39mon_select,\n\u001b[0;32m    103\u001b[0m                 useblit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, button\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    104\u001b[0m                 minspanx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minspany\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m    105\u001b[0m                 spancoords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels\u001b[39m\u001b[38;5;124m'\u001b[39m, interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path), \n\u001b[0;32m    111\u001b[0m        analyzer\u001b[38;5;241m.\u001b[39mstats, \n\u001b[0;32m    112\u001b[0m        analyzer\u001b[38;5;241m.\u001b[39mhist_data)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backend_bases.py:3553\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3553\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:520\u001b[0m, in \u001b[0;36mFigureManagerTk.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    518\u001b[0m manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     \u001b[43mfirst_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_data = {}\n",
    "        self.background = None\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        plt.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_rois()\n",
    "            plt.close()\n",
    "\n",
    "    def process_rois(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.background[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Calculate histogram data\n",
    "            counts, bins = np.histogram(combined_pixels, bins=50)\n",
    "            self.hist_data = {\n",
    "                'bin_starts': bins[:-1],\n",
    "                'bin_ends': bins[1:],\n",
    "                'counts': counts\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    analyzer = ROIAnalyzer()\n",
    "    analyzer.background = background\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    analyzer.ax = ax\n",
    "    ax.imshow(background, cmap='gray')\n",
    "    ax.set_title(f\"Select 2 ROIs\\n{os.path.basename(file_path)} ({year})\")\n",
    "    \n",
    "    RectangleSelector(ax, analyzer.on_select,\n",
    "                    useblit=True, button=[1],\n",
    "                    minspanx=5, minspany=5,\n",
    "                    spancoords='pixels', interactive=True)\n",
    "    \n",
    "    plt.show(block=True)\n",
    "    plt.close()\n",
    "    \n",
    "    return (os.path.basename(file_path), \n",
    "           analyzer.stats, \n",
    "           analyzer.hist_data)\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_records = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            # Collect statistics\n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            # Collect histogram data\n",
    "            hist_records.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Bin_Starts': hist['bin_starts'],\n",
    "                'Bin_Ends': hist['bin_ends'],\n",
    "                'Counts': hist['counts']\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_records\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with two sheets\n",
    "with pd.ExcelWriter('analysis_results.xlsx') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "    \n",
    "    # Histogram data sheet\n",
    "    hist_expanded = hist_df.explode(['Bin_Starts', 'Bin_Ends', 'Counts'])\n",
    "    hist_expanded.to_excel(writer, sheet_name='Histograms', index=False)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')  # Try 'Qt5Agg' if this doesn't work\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_data = {}\n",
    "\n",
    "        # Setup plot\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        \n",
    "        # Create rectangle selector\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        \n",
    "        # Connect event handler\n",
    "        self.fig.canvas.mpl_connect('key_press_event', self.close_fig)\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        \"\"\"Handle rectangle selection events.\"\"\"\n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.calculate_stats()\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def close_fig(self, event):\n",
    "        \"\"\"Handle window closing.\"\"\"\n",
    "        if event.key == 'enter':\n",
    "            plt.close(self.fig)\n",
    "\n",
    "    def calculate_stats(self):\n",
    "        \"\"\"Calculate statistics from selected ROIs.\"\"\"\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Calculate histogram data\n",
    "            counts, bins = np.histogram(combined_pixels, bins=50)\n",
    "            self.hist_data = {\n",
    "                'bin_starts': bins[:-1],\n",
    "                'bin_ends': bins[1:],\n",
    "                'counts': counts\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    \"\"\"Read HDF4 file and verify data structure.\"\"\"\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        \n",
    "        if data.shape[0] < 2:\n",
    "            raise ValueError(\"Invalid dataset structure\")\n",
    "            \n",
    "        background = data[1, :, :]  # Second element is background\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    \"\"\"Analyze a single file with interactive ROI selection.\"\"\"\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    selector = ROISelector(background, filename, year)\n",
    "    \n",
    "    return filename, selector.stats, selector.hist_data\n",
    "\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_records = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            # Collect statistics\n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            # Collect histogram data\n",
    "            hist_records.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Bin_Starts': hist['bin_starts'],\n",
    "                'Bin_Ends': hist['bin_ends'],\n",
    "                'Counts': hist['counts']\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_records\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with two sheets\n",
    "with pd.ExcelWriter('analysis_results.xlsx') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "    \n",
    "    # Histogram data sheet\n",
    "    hist_expanded = hist_df.explode(['Bin_Starts', 'Bin_Ends', 'Counts'])\n",
    "    hist_expanded.to_excel(writer, sheet_name='Histograms', index=False)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")\n",
    "\n",
    "# Rest of the processing functions remain the same as previous version\n",
    "# (process_year, main loop, Excel export, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 172\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2026\u001b[39m):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m     year_stat, year_hists \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m year_stat:\n\u001b[0;32m    174\u001b[0m         all_stats\u001b[38;5;241m.\u001b[39mappend(year_stat)\n",
      "Cell \u001b[1;32mIn[1], line 141\u001b[0m, in \u001b[0;36mprocess_year\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m hdf_files:\n\u001b[0;32m    140\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(year_dir, file_name)\n\u001b[1;32m--> 141\u001b[0m     filename, stats, hist_image \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stats \u001b[38;5;129;01mand\u001b[39;00m hist_image:\n\u001b[0;32m    144\u001b[0m         category \u001b[38;5;241m=\u001b[39m categorize_file(filename)\n",
      "Cell \u001b[1;32mIn[1], line 120\u001b[0m, in \u001b[0;36manalyze_file\u001b[1;34m(file_path, year)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\n\u001b[1;32m--> 120\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mROIAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename, analyzer\u001b[38;5;241m.\u001b[39mstats, analyzer\u001b[38;5;241m.\u001b[39mhist_image\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mROIAnalyzer.__init__\u001b[1;34m(self, image, filename, year)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect 2 ROIs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselector \u001b[38;5;241m=\u001b[39m RectangleSelector(\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_select,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n\u001b[1;32m---> 50\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backend_bases.py:3553\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3553\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:520\u001b[0m, in \u001b[0;36mFigureManagerTk.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    518\u001b[0m manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     \u001b[43mfirst_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     manager_class\u001b[38;5;241m.\u001b[39m_owns_mainloop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_image = None\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_data()\n",
    "            plt.close()\n",
    "\n",
    "    def process_data(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Generate and save histogram plot\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            ax.hist(combined_pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_title(f\"Histogram\\n{self.filename}\")\n",
    "            ax.set_xlabel(\"Pixel Value\")\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "            \n",
    "            # Save plot to Bytes buffer\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            self.hist_image = buf.getvalue()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats, analyzer.hist_image\n",
    "\n",
    "\n",
    "    # Histogram sheet code remains the same...\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist_image = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist_image:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Histogram': hist_image\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with images\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "\n",
    "    # Histograms sheet\n",
    "    workbook = writer.book\n",
    "    hist_sheet = workbook.add_worksheet('Histograms')\n",
    "    \n",
    "    # Write headers\n",
    "    headers = ['Year', 'Filename', 'Category', 'Histogram']\n",
    "    hist_sheet.write_row(0, 0, headers)\n",
    "    \n",
    "    # Set column widths\n",
    "    hist_sheet.set_column(0, 2, 15)\n",
    "    hist_sheet.set_column(3, 3, 30)\n",
    "    \n",
    "    for row_idx, hist in enumerate(hist_df.to_dict('records'), start=1):\n",
    "        # Write metadata\n",
    "        hist_sheet.write(row_idx, 0, hist['Year'])\n",
    "        hist_sheet.write(row_idx, 1, hist['Filename'])\n",
    "        hist_sheet.write(row_idx, 2, hist['Category'])\n",
    "        \n",
    "        # Insert histogram image\n",
    "        img_stream = BytesIO(hist['Histogram'])\n",
    "        hist_sheet.insert_image(\n",
    "            row_idx, 3,\n",
    "            hist['Filename'],\n",
    "            {'image_data': img_stream, 'x_offset': 5, 'y_offset': 5}\n",
    "        )\n",
    "        \n",
    "        # Set row height\n",
    "        hist_sheet.set_row(row_idx, 100)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_image = None\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_data()\n",
    "            plt.close()\n",
    "\n",
    "    def process_data(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Generate and save histogram plot\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            ax.hist(combined_pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_title(f\"Histogram\\n{self.filename}\")\n",
    "            ax.set_xlabel(\"Pixel Value\")\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "            \n",
    "            # Save plot to Bytes buffer\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            self.hist_image = buf.getvalue()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats, analyzer.hist_image\n",
    "\n",
    "\n",
    "    # Histogram sheet code remains the same...\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist_image = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist_image:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Histogram': hist_image\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with images\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "\n",
    "    # Histograms sheet\n",
    "    workbook = writer.book\n",
    "    hist_sheet = workbook.add_worksheet('Histograms')\n",
    "    \n",
    "    # Write headers\n",
    "    headers = ['Year', 'Filename', 'Category', 'Histogram']\n",
    "    hist_sheet.write_row(0, 0, headers)\n",
    "    \n",
    "    # Set column widths\n",
    "    hist_sheet.set_column(0, 2, 15)\n",
    "    hist_sheet.set_column(3, 3, 30)\n",
    "    \n",
    "    for row_idx, hist in enumerate(hist_df.to_dict('records'), start=1):\n",
    "        # Write metadata\n",
    "        hist_sheet.write(row_idx, 0, hist['Year'])\n",
    "        hist_sheet.write(row_idx, 1, hist['Filename'])\n",
    "        hist_sheet.write(row_idx, 2, hist['Category'])\n",
    "        \n",
    "        # Insert histogram image\n",
    "        img_stream = BytesIO(hist['Histogram'])\n",
    "        hist_sheet.insert_image(\n",
    "            row_idx, 3,\n",
    "            hist['Filename'],\n",
    "            {'image_data': img_stream, 'x_offset': 5, 'y_offset': 5}\n",
    "        )\n",
    "        \n",
    "        # Set row height\n",
    "        hist_sheet.set_row(row_idx, 100)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhdf.SD import SD, SDC\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "\n",
    "# List with paths to the files\n",
    "names_list = [\n",
    "    'CCD_gain/IAW_1000msSlowRamp_lighton_2.hdf',\n",
    "    'CCD_gain/IAW_1000msSlowRamp_lighton_3.hdf',\n",
    "    'CCD_gain/IAW_1000msSlowRamp_lightoff_3.hdf',\n",
    "    'CCD_gain/IAW_1000msSlowRamp_lightoff_1.hdf'\n",
    "]\n",
    "\n",
    "# List with flat arrays after subtracting the dark current \n",
    "flats = []\n",
    "\n",
    "# Open hdf files and process data\n",
    "for fname in names_list:\n",
    "    hdf = SD(fname, SDC.READ)\n",
    "    dataset = hdf.select('Streak_array')\n",
    "    data = dataset[:,:].astype(np.float64)\n",
    "    hdf.end()\n",
    "    flat = data[0] - data[1]\n",
    "    flats.append(flat)\n",
    "\n",
    "flats_add = []\n",
    "flats_diff = []\n",
    "\n",
    "# Process pairs of flats\n",
    "for i in range(0, len(flats), 2):\n",
    "    pair = flats[i:i+2]\n",
    "    if len(pair) != 2:\n",
    "        raise ValueError(\"Uneven number of flats for averaging\")\n",
    "    avg_flat = (pair[0] + pair[1]) / 2.0\n",
    "    flats_add.append(avg_flat)\n",
    "    diff = pair[0] - pair[1]\n",
    "    flats_diff.append(diff)\n",
    "\n",
    "diff_box = []\n",
    "roi_box = []\n",
    "\n",
    "# Function to handle ROI selection\n",
    "def onselect(eclick, erelease, roi_coords):\n",
    "    x1 = int(eclick.xdata)\n",
    "    y1 = int(eclick.ydata)\n",
    "    x2 = int(erelease.xdata)\n",
    "    y2 = int(erelease.ydata)\n",
    "    x_start, x_end = sorted([x1, x2])\n",
    "    y_start, y_end = sorted([y1, y2])\n",
    "    roi_coords.append((y_start, y_end, x_start, x_end))\n",
    "    if len(roi_coords) >= 5:\n",
    "        plt.close()\n",
    "\n",
    "# Loop through each averaged flat to select ROIs\n",
    "for idx in range(len(flats_add)):\n",
    "    current_flat = flats_add[idx]\n",
    "    current_diff = flats_diff[idx]\n",
    "    roi_coords = []\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(current_flat, cmap='prism')\n",
    "    ax.set_title(f'Pair {idx+1}: Select 5 ROIs, then close window')\n",
    "    \n",
    "    # Connect the RectangleSelector\n",
    "    rs = RectangleSelector(ax, lambda eclick, erelease: onselect(eclick, erelease, roi_coords),\n",
    "                           useblit=True, button=[1],\n",
    "                           minspanx=5, minspany=5,\n",
    "                           spancoords='pixels', interactive=True)\n",
    "    \n",
    "    plt.show(block=True)\n",
    "    \n",
    "    # Ensure exactly 5 ROIs are selected\n",
    "    if len(roi_coords) != 5:\n",
    "        raise ValueError(f\"Exactly 5 ROIs must be selected for pair {idx+1}, but {len(roi_coords)} were provided.\")\n",
    "    \n",
    "    # Extract ROIs from current_flat and current_diff\n",
    "    for coords in roi_coords:\n",
    "        y_start, y_end, x_start, x_end = coords\n",
    "        roi = current_flat[y_start:y_end, x_start:x_end]\n",
    "        roi_box.append(roi)\n",
    "        d_roi = current_diff[y_start:y_end, x_start:x_end]\n",
    "        diff_box.append(d_roi)\n",
    "\n",
    "# Calculate variances and means\n",
    "variances_100 = []\n",
    "means_100 = []\n",
    "for i in range(len(diff_box)):\n",
    "    stdev = np.std(diff_box[i])\n",
    "    variance = (stdev ** 2) / 2\n",
    "    variances_100.append(variance)\n",
    "    mean = np.mean(roi_box[i])\n",
    "    means_100.append(mean)\n",
    "\n",
    "coordinates = list(zip(means_100, variances_100))\n",
    "#print(coordinates)\n",
    "\n",
    "# Plotting\n",
    "x = [point[0] for point in coordinates]\n",
    "y = [point[1] for point in coordinates]\n",
    "\n",
    "plt.plot(x, y, 'o', color='blue', markersize=8)\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('1000ms Lights on')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Linear regression and plot\n",
    "if len(coordinates) < 2:\n",
    "    print(\"Error: At least two points are required to compute a slope.\")\n",
    "else:\n",
    "    x = np.array([point[0] for point in coordinates])\n",
    "    y = np.array([point[1] for point in coordinates])\n",
    "    \n",
    "    if np.all(x == x[0]):\n",
    "        print(\"The line is vertical; slope is undefined.\")\n",
    "    else:\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        print(f\"The slope of the line is {slope:.2f}\")\n",
    "        \n",
    "        plt.scatter(x, y, color='red', label='Data Points')\n",
    "        plt.plot(x, slope * x + intercept, label=f'Line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Mean')\n",
    "        plt.ylabel('Variance')\n",
    "        plt.title('1000ms Lights on')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter(\n",
    "    'analysis_results.xlsx',\n",
    "    engine='xlsxwriter',\n",
    "    engine_kwargs={'options': {'nan_inf_to_errors': True}}\n",
    ") as writer:\n",
    "    # Write statistics data starting at row 3 (Excel row 4)\n",
    "    df_stats.to_excel(writer, sheet_name='Statistics', index=False, startrow=3)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    stats_sheet = writer.sheets['Statistics']\n",
    "    \n",
    "    # Create header format\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    # Write and merge headers\n",
    "    # Year header (rows 1-2 in Excel)\n",
    "    stats_sheet.merge_range('A1:A2', 'Year', header_format)\n",
    "    \n",
    "    # Category headers (rows 1-2)\n",
    "    col_idx = 1\n",
    "    for category in categories:\n",
    "        stats_sheet.merge_range(0, col_idx, 0, col_idx+3, category, header_format)\n",
    "        for i, metric in enumerate(['mean', 'median', 'stdv', 'total']):\n",
    "            stats_sheet.write(1, col_idx+i, metric, header_format)\n",
    "        col_idx += 4\n",
    "    \n",
    "    # Write data with proper alignment (starting at row 3)\n",
    "    num_format = workbook.add_format({'num_format': '0.000'})\n",
    "    total_format = workbook.add_format({'num_format': '#,##0'})\n",
    "    \n",
    "    for df_row in range(len(df_stats)):\n",
    "        excel_row = df_row + 3  # Data starts at Excel row 4\n",
    "        # Year column\n",
    "        stats_sheet.write(excel_row, 0, df_stats.iloc[df_row, 0])\n",
    "        \n",
    "        # Data columns\n",
    "        for col in range(1, len(df_stats.columns)):\n",
    "            value = df_stats.iloc[df_row, col]\n",
    "            if pd.isna(value):\n",
    "                stats_sheet.write_blank(excel_row, col, None)\n",
    "            elif (col % 4) == 0:  # Total columns\n",
    "                stats_sheet.write(excel_row, col, value, total_format)\n",
    "            else:\n",
    "                stats_sheet.write(excel_row, col, value, num_format)\n",
    "    \n",
    "    # Set column widths\n",
    "    stats_sheet.set_column(0, 0, 10)  # Year column\n",
    "    for col in range(1, len(df_stats.columns)):\n",
    "        stats_sheet.set_column(col, col, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Histogram sheet code remains the same...\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist_image = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist_image:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Histogram': hist_image\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with images\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_image = None\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_data()\n",
    "            plt.close()\n",
    "\n",
    "    def process_data(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Generate and save histogram plot\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            ax.hist(combined_pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_title(f\"Histogram\\n{self.filename}\")\n",
    "            ax.set_xlabel(\"Pixel Value\")\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "            \n",
    "            # Save plot to Bytes buffer\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            self.hist_image = buf.getvalue()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats, analyzer.hist_image\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_records = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], \n",
    "        'iaw_ross': [],\n",
    "        'epw_ccd': [], \n",
    "        'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist:\n",
    "            category = categorize_file(filename)\n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "    \n",
    "    # Aggregate statistics with formatted column names\n",
    "    category_order = ['iaw_ccd', 'iaw_ross', 'epw_ccd', 'epw_ross']\n",
    "    for category in category_order:\n",
    "        entries = category_data[category]\n",
    "        formatted_category = category.replace('_', ' ')\n",
    "        \n",
    "        if entries:\n",
    "            year_stats[f\"{formatted_category} - mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{formatted_category} - median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{formatted_category} - std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{formatted_category} - total\"] = np.sum([e['total'] for e in entries])\n",
    "        else:\n",
    "            year_stats[f\"{formatted_category} - mean\"] = np.nan\n",
    "            year_stats[f\"{formatted_category} - median\"] = np.nan\n",
    "            year_stats[f\"{formatted_category} - std\"] = np.nan\n",
    "            year_stats[f\"{formatted_category} - total\"] = 0\n",
    "\n",
    "    return year_stats, hist_records\n",
    "\n",
    "# Define column order for Excel output\n",
    "column_order = ['Year']\n",
    "categories = ['iaw_ccd', 'iaw_ross', 'epw_ccd', 'epw_ross']\n",
    "for category in categories:\n",
    "    formatted = category.replace('_', ' ')\n",
    "    column_order += [\n",
    "        f\"{formatted} - mean\",\n",
    "        f\"{formatted} - median\",\n",
    "        f\"{formatted} - std\",\n",
    "        f\"{formatted} - total\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# After main processing loop:\n",
    "stats_df = pd.DataFrame(all_stats).reindex(columns=column_order)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "# Save to Excel with images\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "    \n",
    "    # Histograms sheet\n",
    "    workbook = writer.book\n",
    "    hist_sheet = workbook.add_worksheet('Histograms')\n",
    "    \n",
    "    # Write headers\n",
    "    headers = ['Year', 'Filename', 'Category', 'Histogram']\n",
    "    hist_sheet.write_row(0, 0, headers)\n",
    "    \n",
    "    # Set column widths\n",
    "    hist_sheet.set_column(0, 2, 15)\n",
    "    hist_sheet.set_column(3, 3, 30)\n",
    "    \n",
    "    for row_idx, hist in enumerate(hist_df.to_dict('records'), start=1):\n",
    "        # Write metadata\n",
    "        hist_sheet.write(row_idx, 0, hist['Year'])\n",
    "        hist_sheet.write(row_idx, 1, hist['Filename'])\n",
    "        hist_sheet.write(row_idx, 2, hist['Category'])\n",
    "        \n",
    "        # Insert histogram image\n",
    "        img_stream = BytesIO(hist['Histogram'])\n",
    "        hist_sheet.insert_image(\n",
    "            row_idx, 3,\n",
    "            hist['Filename'],\n",
    "            {'image_data': img_stream, 'x_offset': 5, 'y_offset': 5}\n",
    "        )\n",
    "        \n",
    "        # Set row height\n",
    "        hist_sheet.set_row(row_idx, 100)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Writing to Excel with MultiIndex columns and no index ('index'=False) is not yet implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Save to Excel with formatting\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis_results.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlsxwriter\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m--> 181\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     workbook \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39mbook\n\u001b[0;32m    184\u001b[0m     worksheet \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39msheets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSheet1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\io\\formats\\excel.py:952\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 952\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_cells\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformatted_cells\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:261\u001b[0m, in \u001b[0;36mXlsxWriter._write_cells\u001b[1;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_freeze_panes(freeze_panes):\n\u001b[0;32m    259\u001b[0m     wks\u001b[38;5;241m.\u001b[39mfreeze_panes(\u001b[38;5;241m*\u001b[39m(freeze_panes))\n\u001b[1;32m--> 261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m cells:\n\u001b[0;32m    262\u001b[0m     val, fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_with_fmt(cell\u001b[38;5;241m.\u001b[39mval)\n\u001b[0;32m    264\u001b[0m     stylekey \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(cell\u001b[38;5;241m.\u001b[39mstyle)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\io\\formats\\excel.py:889\u001b[0m, in \u001b[0;36mExcelFormatter.get_formatted_cells\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_formatted_cells\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[ExcelCell]:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_header(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_body()):\n\u001b[0;32m    890\u001b[0m         cell\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_value(cell\u001b[38;5;241m.\u001b[39mval)\n\u001b[0;32m    891\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cell\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pandas\\io\\formats\\excel.py:617\u001b[0m, in \u001b[0;36mExcelFormatter._format_header_mi\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m--> 617\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting to Excel with MultiIndex columns and no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=False) is not yet implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    620\u001b[0m         )\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_aliases \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader):\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Writing to Excel with MultiIndex columns and no index ('index'=False) is not yet implemented."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.calculate_stats()\n",
    "            plt.close()\n",
    "\n",
    "    def calculate_stats(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'stdv': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    \n",
    "    categories = {\n",
    "        'iaw_ccd': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'iaw_ross': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'epw_ccd': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'epw_ross': {'means': [], 'medians': [], 'stdvs': [], 'totals': []}\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats:\n",
    "            category = categorize_file(filename)\n",
    "            if category in categories:\n",
    "                categories[category]['means'].append(stats['mean'])\n",
    "                categories[category]['medians'].append(stats['median'])\n",
    "                categories[category]['stdvs'].append(stats['stdv'])\n",
    "                categories[category]['totals'].append(stats['total'])\n",
    "    \n",
    "    # Calculate averages and totals\n",
    "    for cat, data in categories.items():\n",
    "        prefix = cat.replace('_', ' ')\n",
    "        year_data[f\"{prefix} - mean\"] = np.mean(data['means']) if data['means'] else np.nan\n",
    "        year_data[f\"{prefix} - median\"] = np.mean(data['medians']) if data['medians'] else np.nan\n",
    "        year_data[f\"{prefix} - stdv\"] = np.mean(data['stdvs']) if data['stdvs'] else np.nan\n",
    "        year_data[f\"{prefix} - total\"] = np.sum(data['totals']) if data['totals'] else 0\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Define categories and metrics\n",
    "categories = ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']\n",
    "metrics = ['mean', 'median', 'stdv', 'total']\n",
    "\n",
    "# Create column structure\n",
    "columns = pd.MultiIndex.from_tuples(\n",
    "    [('Year', '')] + \n",
    "    [(cat, metric) for cat in categories for metric in metrics],\n",
    "    names=['Category', 'Metric']\n",
    ")\n",
    "\n",
    "# Prepare data rows\n",
    "formatted_data = []\n",
    "for entry in all_data:\n",
    "    row = [entry['Year']]\n",
    "    for cat in categories:\n",
    "        row += [\n",
    "            entry.get(f\"{cat} - mean\", np.nan),\n",
    "            entry.get(f\"{cat} - median\", np.nan),\n",
    "            entry.get(f\"{cat} - stdv\", np.nan),\n",
    "            entry.get(f\"{cat} - total\", 0)\n",
    "        ]\n",
    "    formatted_data.append(row)\n",
    "\n",
    "# Create DataFrame with correct column count\n",
    "df = pd.DataFrame(formatted_data, columns=columns)\n",
    "\n",
    "# Save to Excel with formatting\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    df.to_excel(writer, index=False, startrow=1)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    \n",
    "    # Merge category headers\n",
    "    for col_idx, category in enumerate([''] + categories):\n",
    "        if col_idx == 0:  # Skip Year column\n",
    "            continue\n",
    "        worksheet.merge_range(0, col_idx*4-3, 0, col_idx*4, category)\n",
    "    \n",
    "    # Write metric subheaders\n",
    "    metric_headers = ['Year'] + metrics*len(categories)\n",
    "    for col_idx, header in enumerate(metric_headers):\n",
    "        worksheet.write(1, col_idx, header)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results successfully saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# After processing all data, create a flat DataFrame\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.calculate_stats()\n",
    "            plt.close()\n",
    "\n",
    "    def calculate_stats(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'stdv': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_data = {'Year': year}\n",
    "    \n",
    "    categories = {\n",
    "        'iaw_ccd': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'iaw_ross': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'epw_ccd': {'means': [], 'medians': [], 'stdvs': [], 'totals': []},\n",
    "        'epw_ross': {'means': [], 'medians': [], 'stdvs': [], 'totals': []}\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats:\n",
    "            category = categorize_file(filename)\n",
    "            if category in categories:\n",
    "                categories[category]['means'].append(stats['mean'])\n",
    "                categories[category]['medians'].append(stats['median'])\n",
    "                categories[category]['stdvs'].append(stats['stdv'])\n",
    "                categories[category]['totals'].append(stats['total'])\n",
    "    \n",
    "    # Calculate averages and totals\n",
    "    for cat, data in categories.items():\n",
    "        prefix = cat.replace('_', ' ')\n",
    "        year_data[f\"{prefix} - mean\"] = np.mean(data['means']) if data['means'] else np.nan\n",
    "        year_data[f\"{prefix} - median\"] = np.mean(data['medians']) if data['medians'] else np.nan\n",
    "        year_data[f\"{prefix} - stdv\"] = np.mean(data['stdvs']) if data['stdvs'] else np.nan\n",
    "        year_data[f\"{prefix} - total\"] = np.sum(data['total']) if data['total'] else 0\n",
    "    \n",
    "    return year_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "flat_columns = ['Year']\n",
    "for category in ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']:\n",
    "    flat_columns += [f\"{category} - {metric}\" for metric in ['mean', 'median', 'stdv', 'total']]\n",
    "\n",
    "flat_data = []\n",
    "for entry in all_data:\n",
    "    row = [entry['Year']]\n",
    "    for category in ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']:\n",
    "        row += [\n",
    "            entry.get(f\"{category} - mean\", np.nan),\n",
    "            entry.get(f\"{category} - median\", np.nan),\n",
    "            entry.get(f\"{category} - stdv\", np.nan),\n",
    "            entry.get(f\"{category} - total\", 0)\n",
    "        ]\n",
    "    flat_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(flat_data, columns=flat_columns)\n",
    "\n",
    "# After creating the DataFrame:\n",
    "\n",
    "with pd.ExcelWriter(\n",
    "    'analysis_results.xlsx',\n",
    "    engine='xlsxwriter',\n",
    "    engine_kwargs={'options': {'nan_inf_to_errors': True}}\n",
    ") as writer:\n",
    "    df.to_excel(writer, sheet_name='Statistics', index=False, startrow=2)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Statistics']\n",
    "    \n",
    "    # Category headers formatting\n",
    "    category_headers = ['Year', 'iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']\n",
    "    category_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    # Merge and format headers\n",
    "    worksheet.merge_range('A1:A2', 'Year', category_format)\n",
    "    for idx, category in enumerate(category_headers[1:], start=1):\n",
    "        start_col = 1 + (idx-1)*4\n",
    "        end_col = start_col + 3\n",
    "        worksheet.merge_range(\n",
    "            0, start_col, 0, end_col,\n",
    "            category,\n",
    "            category_format\n",
    "        )\n",
    "    \n",
    "    # Metric subheaders\n",
    "    metric_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'border': 1\n",
    "    })\n",
    "    metrics = ['mean', 'median', 'stdv', 'total']\n",
    "    for col in range(1, len(df.columns)):\n",
    "        if (col-1) % 4 == 0:\n",
    "            worksheet.write(1, col, metrics[0], metric_format)\n",
    "            worksheet.write(1, col+1, metrics[1], metric_format)\n",
    "            worksheet.write(1, col+2, metrics[2], metric_format)\n",
    "            worksheet.write(1, col+3, metrics[3], metric_format)\n",
    "    \n",
    "    # Data formatting\n",
    "    num_format = workbook.add_format({'num_format': '0.000'})\n",
    "    total_format = workbook.add_format({'num_format': '#,##0'})\n",
    "    \n",
    "    for row_idx in range(2, len(df)+2):\n",
    "        # Year column\n",
    "        worksheet.write(row_idx, 0, df.iloc[row_idx-2, 0])\n",
    "        \n",
    "        # Data columns\n",
    "        for col_idx in range(1, len(df.columns)):\n",
    "            value = df.iloc[row_idx-2, col_idx]\n",
    "            if pd.isna(value):\n",
    "                worksheet.write_blank(row_idx, col_idx, None)\n",
    "            elif (col_idx % 4) == 0:  # Total columns\n",
    "                worksheet.write(row_idx, col_idx, value, total_format)\n",
    "            else:\n",
    "                worksheet.write(row_idx, col_idx, value, num_format)\n",
    "    \n",
    "    # Column widths\n",
    "    worksheet.set_column(0, 0, 10)  # Year column\n",
    "    for col in range(1, len(df.columns)):\n",
    "        worksheet.set_column(col, col, 12)\n",
    "\n",
    "print(\"Analysis results successfully saved to analysis_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Configure matplotlib backend\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROIAnalyzer:\n",
    "    def __init__(self, image, filename, year):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.rois = []\n",
    "        self.stats = {}\n",
    "        self.hist_image = None\n",
    "\n",
    "        # Setup plot and selector\n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs\\n{filename} ({year})\")\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax,\n",
    "            self.on_select,\n",
    "            useblit=True,\n",
    "            button=[1],\n",
    "            minspanx=5,\n",
    "            minspany=5,\n",
    "            spancoords='pixels',\n",
    "            interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            self.process_data()\n",
    "            plt.close()\n",
    "\n",
    "    def process_data(self):\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in self.rois:\n",
    "            try:\n",
    "                roi_data = self.image[y:y+h, x:x+w]\n",
    "                combined_pixels.extend(roi_data.flatten())\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if combined_pixels:\n",
    "            # Calculate statistics\n",
    "            self.stats = {\n",
    "                'mean': np.mean(combined_pixels),\n",
    "                'median': np.median(combined_pixels),\n",
    "                'std': np.std(combined_pixels),\n",
    "                'total': len(combined_pixels)\n",
    "            }\n",
    "            \n",
    "            # Generate and save histogram plot\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            ax.hist(combined_pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_title(f\"Histogram\\n{self.filename}\")\n",
    "            ax.set_xlabel(\"Pixel Value\")\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "            \n",
    "            # Save plot to Bytes buffer\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            self.hist_image = buf.getvalue()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    analyzer = ROIAnalyzer(background, filename, year)\n",
    "    return filename, analyzer.stats, analyzer.hist_image\n",
    "\n",
    "\n",
    "    # Histogram sheet code remains the same...\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename, stats, hist_image = analyze_file(file_path, year)\n",
    "        \n",
    "        if stats and hist_image:\n",
    "            category = categorize_file(filename)\n",
    "            \n",
    "            if category in category_data:\n",
    "                category_data[category].append(stats)\n",
    "            \n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category,\n",
    "                'Histogram': hist_image\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for category, entries in category_data.items():\n",
    "        if entries:\n",
    "            year_stats[f\"{category}_mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{category}_median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{category}_std\"] = np.mean([e['std'] for e in entries])\n",
    "            year_stats[f\"{category}_total\"] = np.sum([e['total'] for e in entries])\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_stats = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_stats.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create DataFrames\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "hist_df = pd.DataFrame(all_hists)\n",
    "\n",
    "# Save to Excel with images\n",
    "with pd.ExcelWriter('analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Statistics sheet\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "\n",
    "    # Histograms sheet\n",
    "    workbook = writer.book\n",
    "    hist_sheet = workbook.add_worksheet('Histograms')\n",
    "    \n",
    "    # Write headers\n",
    "    headers = ['Year', 'Filename', 'Category', 'Histogram']\n",
    "    hist_sheet.write_row(0, 0, headers)\n",
    "    \n",
    "    # Set column widths\n",
    "    hist_sheet.set_column(0, 2, 15)\n",
    "    hist_sheet.set_column(3, 3, 30)\n",
    "    \n",
    "    for row_idx, hist in enumerate(hist_df.to_dict('records'), start=1):\n",
    "        # Write metadata\n",
    "        hist_sheet.write(row_idx, 0, hist['Year'])\n",
    "        hist_sheet.write(row_idx, 1, hist['Filename'])\n",
    "        hist_sheet.write(row_idx, 2, hist['Category'])\n",
    "        \n",
    "        # Insert histogram image\n",
    "        img_stream = BytesIO(hist['Histogram'])\n",
    "        hist_sheet.insert_image(\n",
    "            row_idx, 3,\n",
    "            hist['Filename'],\n",
    "            {'image_data': img_stream, 'x_offset': 5, 'y_offset': 5}\n",
    "        )\n",
    "        \n",
    "        # Set row height\n",
    "        hist_sheet.set_row(row_idx, 100)\n",
    "\n",
    "print(\"Analysis results saved to analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class RossROIManager:\n",
    "    def __init__(self):\n",
    "        self.rois = {\n",
    "            'iaw_ross': None,\n",
    "            'epw_ross': None\n",
    "        }\n",
    "        self.first_files_processed = {\n",
    "            'iaw_ross': False,\n",
    "            'epw_ross': False\n",
    "        }\n",
    "\n",
    "    def get_rois(self, category):\n",
    "        return self.rois[category]\n",
    "\n",
    "    def set_rois(self, category, rois):\n",
    "        self.rois[category] = rois\n",
    "        self.first_files_processed[category] = True\n",
    "\n",
    "    def needs_roi_selection(self, category):\n",
    "        return not self.first_files_processed[category]\n",
    "\n",
    "ross_manager = RossROIManager()\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self, image, filename, year, category):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.category = category\n",
    "        self.rois = []\n",
    "        \n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs for {category}\\n{filename} ({year})\")\n",
    "        \n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax, self.on_select,\n",
    "            useblit=True, button=[1],\n",
    "            minspanx=5, minspany=5,\n",
    "            spancoords='pixels', interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            plt.close()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_file(file_path, year, category):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None\n",
    "\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    if 'ccd' in category:\n",
    "        # Use full frame for CCD categories\n",
    "        combined_pixels = background.flatten()\n",
    "    else:\n",
    "        # Ross categories\n",
    "        if ross_manager.needs_roi_selection(category):\n",
    "            # First file in category - get ROIs\n",
    "            selector = ROISelector(background, filename, year, category)\n",
    "            ross_manager.set_rois(category, selector.rois)\n",
    "        \n",
    "        # Get stored ROIs\n",
    "        rois = ross_manager.get_rois(category)\n",
    "        combined_pixels = []\n",
    "        for x, y, w, h in rois:\n",
    "            roi_data = background[y:y+h, x:x+w]\n",
    "            combined_pixels.extend(roi_data.flatten())\n",
    "\n",
    "    if len(combined_pixels) > 0:\n",
    "        return {\n",
    "            'mean': np.mean(combined_pixels),\n",
    "            'median': np.median(combined_pixels),\n",
    "            'stdv': np.std(combined_pixels),\n",
    "            'total': len(combined_pixels)\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename = os.path.basename(file_path)\n",
    "        category = categorize_file(filename)\n",
    "        \n",
    "        if category not in category_data:\n",
    "            continue\n",
    "            \n",
    "        stats = analyze_file(file_path, year, category)\n",
    "        if stats:\n",
    "            category_data[category].append(stats)\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for cat, entries in category_data.items():\n",
    "        prefix = cat.replace('_', ' ')\n",
    "        if entries:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{prefix} - median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.mean([e['stdv'] for e in entries])\n",
    "            year_stats[f\"{prefix} - total\"] = np.sum([e['total'] for e in entries])\n",
    "        else:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.nan\n",
    "            year_stats[f\"{prefix} - median\"] = np.nan\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.nan\n",
    "            year_stats[f\"{prefix} - total\"] = 0\n",
    "    \n",
    "    return year_stats\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_result = process_year(year)\n",
    "    if year_result:\n",
    "        all_data.append(year_result)\n",
    "\n",
    "# Create and save Excel report\n",
    "if all_data:\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Define column order\n",
    "    categories = ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']\n",
    "    column_order = ['Year']\n",
    "    for cat in categories:\n",
    "        column_order += [f\"{cat} - {metric}\" for metric in ['mean', 'median', 'stdv', 'total']]\n",
    "    \n",
    "    df = df.reindex(columns=column_order)\n",
    "    \n",
    "    # Save to Excel with formatting\n",
    "    with pd.ExcelWriter(\n",
    "        'analysis_results.xlsx',\n",
    "        engine='xlsxwriter',\n",
    "        engine_kwargs={'options': {'nan_inf_to_errors': True}}\n",
    "    ) as writer:\n",
    "        df.to_excel(writer, sheet_name='Statistics', index=False, startrow=2)\n",
    "        \n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Statistics']\n",
    "        \n",
    "        # Create header format\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'align': 'center',\n",
    "            'valign': 'vcenter',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Merge category headers\n",
    "        worksheet.merge_range('A1:A2', 'Year', header_format)\n",
    "        col_idx = 1\n",
    "        for category in categories:\n",
    "            worksheet.merge_range(0, col_idx, 0, col_idx+3, category, header_format)\n",
    "            for i, metric in enumerate(['mean', 'median', 'stdv', 'total']):\n",
    "                worksheet.write(1, col_idx+i, metric, header_format)\n",
    "            col_idx += 4\n",
    "        \n",
    "        # Format numbers\n",
    "        num_format = workbook.add_format({'num_format': '0.000'})\n",
    "        total_format = workbook.add_format({'num_format': '#,##0'})\n",
    "        \n",
    "        for row in range(2, len(df)+2):\n",
    "            worksheet.set_row(row, 20)\n",
    "            for col in range(1, len(df.columns)):\n",
    "                value = df.iloc[row-2, col]\n",
    "                if pd.isna(value):\n",
    "                    worksheet.write_blank(row, col, None)\n",
    "                elif (col % 4) == 0:  # Total columns\n",
    "                    worksheet.write(row, col, value, total_format)\n",
    "                else:\n",
    "                    worksheet.write(row, col, value, num_format)\n",
    "        \n",
    "        # Set column widths\n",
    "        worksheet.set_column(0, 0, 10)  # Year column\n",
    "        for col in range(1, len(df.columns)):\n",
    "            worksheet.set_column(col, col, 15)\n",
    "\n",
    "    print(\"Analysis results saved to analysis_results.xlsx\")\n",
    "else:\n",
    "    print(\"No data processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data/IAW_1000msSlowRamp_lighton_2.hdf: SD: no such file\n"
     ]
    },
    {
     "ename": "HDF4Error",
     "evalue": "SD: no such file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF4Error\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m names_list:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m         hdf \u001b[38;5;241m=\u001b[39m \u001b[43mSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSDC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m hdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStreak_array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m         data \u001b[38;5;241m=\u001b[39m dataset[:, :]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[1;32mc:\\Users\\jher\\AppData\\Local\\anaconda3\\envs\\tsadar-cpu\\lib\\site-packages\\pyhdf\\SD.py:1424\u001b[0m, in \u001b[0;36mSD.__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         mode \u001b[38;5;241m=\u001b[39m SDC\u001b[38;5;241m.\u001b[39mREAD\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m HDF4Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD: no such file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HDF4Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD: bad mode, READ or WRITE must be set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mHDF4Error\u001b[0m: SD: no such file"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "\n",
    "# Configuration parameters\n",
    "ROI_SIZE = 30  # Size of square ROI in pixels\n",
    "NUM_ROIS = 5    # Number of ROIs to select per image\n",
    "\n",
    "# List of file paths\n",
    "names_list = [\n",
    "    '/IAW_1000msSlowRamp_lighton_2.hdf',\n",
    "    'data/IAW_1000msSlowRamp_lighton_3.hdf',\n",
    "    'data/IAW_1000msSlowRamp_lightoff_2.hdf',\n",
    "    'data/IAW_1000msSlowRamp_lightoff_3.hdf'\n",
    "]\n",
    "\n",
    "# Load and process HDF files\n",
    "flats = []\n",
    "for fname in names_list:\n",
    "    try:\n",
    "        hdf = SD(fname, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset[:, :].astype(np.float64)\n",
    "        hdf.end()\n",
    "        flat = data[0] - data[1]\n",
    "        flats.append(flat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Create averaged and difference images\n",
    "flats_add = []\n",
    "flats_diff = []\n",
    "for i in range(0, len(flats), 2):\n",
    "    pair = flats[i:i+2]\n",
    "    if len(pair) != 2:\n",
    "        raise ValueError(\"Uneven number of flats for averaging\")\n",
    "    \n",
    "    flats_add.append((pair[0] + pair[1]) / 2.0)\n",
    "    flats_diff.append(pair[0] - pair[1])\n",
    "\n",
    "# ROI selection and analysis\n",
    "roi_add = []  # Stores ROIs from averaged images\n",
    "roi_diff = []  # Stores corresponding ROIs from difference images\n",
    "stats_add = []  # Statistics for averaged ROIs\n",
    "stats_diff = []  # Statistics for difference ROIs\n",
    "\n",
    "for idx in range(len(flats_add)):\n",
    "    # Display image for ROI selection\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(flats_add[idx], cmap='gray', origin='upper')\n",
    "    ax.set_title(f\"Select {NUM_ROIS} ROIs (click centers) | Image {idx+1}/{len(flats_add)}\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Get ROI centers from user clicks\n",
    "    print(f\"Click {NUM_ROIS} locations for image {idx+1}\")\n",
    "    centers = plt.ginput(NUM_ROIS, timeout=0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Process each selected ROI\n",
    "    for i, (x, y) in enumerate(centers):\n",
    "        # Convert click coordinates to array indices\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        \n",
    "        # Calculate ROI boundaries with edge protection\n",
    "        height, width = flats_add[idx].shape\n",
    "        half = ROI_SIZE // 2\n",
    "        \n",
    "        row_start = max(0, row - half)\n",
    "        row_end = min(height, row + half + (ROI_SIZE % 2))\n",
    "        col_start = max(0, col - half)\n",
    "        col_end = min(width, col + half + (ROI_SIZE % 2))\n",
    "        \n",
    "        # Extract ROIs from both image types\n",
    "        roi_a = flats_add[idx][row_start:row_end, col_start:col_end]\n",
    "        roi_d = flats_diff[idx][row_start:row_end, col_start:col_end]\n",
    "        \n",
    "        # Store ROIs\n",
    "        roi_add.append(roi_a)\n",
    "        roi_diff.append(roi_d)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats_add.append({\n",
    "            'mean': np.mean(roi_a),\n",
    "            'median': np.median(roi_a),\n",
    "            'std': np.std(roi_a),\n",
    "            'var': np.var(roi_a)\n",
    "        })\n",
    "        \n",
    "        stats_diff.append({\n",
    "            'mean': np.mean(roi_d),\n",
    "            'median': np.median(roi_d),\n",
    "            'std': np.std(roi_d),\n",
    "            'var': np.var(roi_d)\n",
    "        })\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"{'ROI #':<6} | {'Type':<6} | {'Mean':<10} | {'Std Dev':<10} | {'Variance':<10} | {'Median':<10}\")\n",
    "print(\"-\"*75)\n",
    "for i in range(len(roi_add)):\n",
    "    print(f\"{i+1:<6} | {'Add':<6} | {stats_add[i]['mean']:10.2f} | {stats_add[i]['std']:10.2f} | {stats_add[i]['var']:10.2f} | {stats_add[i]['median']:10.2f}\")\n",
    "    print(f\"{i+1:<6} | {'Diff':<6} | {stats_diff[i]['mean']:10.2f} | {stats_diff[i]['std']:10.2f} | {stats_diff[i]['var']:10.2f} | {stats_diff[i]['median']:10.2f}\")\n",
    "    print(\"-\"*75)\n",
    "\n",
    "# Optional: Save ROIs and statistics\n",
    "np.savez('roi_data.npz', \n",
    "         roi_add=roi_add,\n",
    "         roi_diff=roi_diff,\n",
    "         stats_add=stats_add,\n",
    "         stats_diff=stats_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class RossROIManager:\n",
    "    def __init__(self):\n",
    "        self.rois = {\n",
    "            'iaw_ross': None,\n",
    "            'epw_ross': None\n",
    "        }\n",
    "        self.first_files_processed = {\n",
    "            'iaw_ross': False,\n",
    "            'epw_ross': False\n",
    "        }\n",
    "\n",
    "    def get_rois(self, category):\n",
    "        return self.rois[category]\n",
    "\n",
    "    def set_rois(self, category, rois):\n",
    "        self.rois[category] = rois\n",
    "        self.first_files_processed[category] = True\n",
    "\n",
    "    def needs_roi_selection(self, category):\n",
    "        return not self.first_files_processed[category]\n",
    "\n",
    "ross_manager = RossROIManager()\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self, image, filename, year, category):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.category = category\n",
    "        self.rois = []\n",
    "        \n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs for {category}\\n{filename} ({year})\")\n",
    "        \n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax, self.on_select,\n",
    "            useblit=True, button=[1],\n",
    "            minspanx=5, minspany=5,\n",
    "            spancoords='pixels', interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            plt.close()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_histogram(pixels, filename, year):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.hist(pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.title(f\"Histogram\\n{filename} ({year})\")\n",
    "    plt.xlabel(\"Pixel Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    return buf.getvalue()\n",
    "\n",
    "def analyze_file(file_path, year, category):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "\n",
    "    filename = os.path.basename(file_path)\n",
    "    histogram = None\n",
    "    \n",
    "    if 'ccd' in category:\n",
    "        # Full frame for CCD\n",
    "        pixels = background.flatten()\n",
    "        histogram = generate_histogram(pixels, filename, year)\n",
    "        stats = {\n",
    "            'mean': np.mean(pixels),\n",
    "            'median': np.median(pixels),\n",
    "            'stdv': np.std(pixels),\n",
    "            'total': len(pixels)\n",
    "        }\n",
    "    else:\n",
    "        # Ross categories\n",
    "        if ross_manager.needs_roi_selection(category):\n",
    "            selector = ROISelector(background, filename, year, category)\n",
    "            ross_manager.set_rois(category, selector.rois)\n",
    "        \n",
    "        rois = ross_manager.get_rois(category)\n",
    "        pixels = []\n",
    "        for x, y, w, h in rois:\n",
    "            roi_data = background[y:y+h, x:x+w]\n",
    "            pixels.extend(roi_data.flatten())\n",
    "        \n",
    "        if pixels:\n",
    "            histogram = generate_histogram(pixels, filename, year)\n",
    "            stats = {\n",
    "                'mean': np.mean(pixels),\n",
    "                'median': np.median(pixels),\n",
    "                'stdv': np.std(pixels),\n",
    "                'total': len(pixels)\n",
    "            }\n",
    "        else:\n",
    "            stats = None\n",
    "\n",
    "    return stats, histogram\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename = os.path.basename(file_path)\n",
    "        category = categorize_file(filename)\n",
    "        \n",
    "        if category not in category_data:\n",
    "            continue\n",
    "            \n",
    "        stats, hist = analyze_file(file_path, year, category)\n",
    "        if stats and hist:\n",
    "            category_data[category].append(stats)\n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category.replace('_', ' '),\n",
    "                'Histogram': hist\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for cat, entries in category_data.items():\n",
    "        prefix = cat.replace('_', ' ')\n",
    "        if entries:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{prefix} - median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.mean([e['stdv'] for e in entries])\n",
    "            year_stats[f\"{prefix} - total\"] = np.sum([e['total'] for e in entries])\n",
    "        else:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.nan\n",
    "            year_stats[f\"{prefix} - median\"] = np.nan\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.nan\n",
    "            year_stats[f\"{prefix} - total\"] = 0\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_data.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create and save Excel report\n",
    "if all_data:\n",
    "    # Statistics sheet\n",
    "    df_stats = pd.DataFrame(all_data)\n",
    "    categories = ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']\n",
    "    column_order = ['Year'] + [\n",
    "        f\"{cat} - {metric}\" for cat in categories \n",
    "        for metric in ['mean', 'median', 'stdv', 'total']\n",
    "    ]\n",
    "    df_stats = df_stats.reindex(columns=column_order)\n",
    "    \n",
    "    # Histograms sheet\n",
    "    df_hists = pd.DataFrame(all_hists)\n",
    "    \n",
    "    # Save to Excel\n",
    "    with pd.ExcelWriter(\n",
    "        'analysis_results.xlsx',\n",
    "        engine='xlsxwriter',\n",
    "        engine_kwargs={'options': {'nan_inf_to_errors': True}}\n",
    "    ) as writer:\n",
    "        # Statistics sheet\n",
    "        df_stats.to_excel(writer, sheet_name='Statistics', index=False, startrow=2)\n",
    "        \n",
    "        # Format statistics sheet\n",
    "        workbook = writer.book\n",
    "        stats_sheet = writer.sheets['Statistics']\n",
    "        \n",
    "        # Merge headers\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True, 'align': 'center', 'valign': 'vcenter', 'border': 1\n",
    "        })\n",
    "        stats_sheet.merge_range('A1:A2', 'Year', header_format)\n",
    "        col_idx = 1\n",
    "        for category in categories:\n",
    "            stats_sheet.merge_range(0, col_idx, 0, col_idx+3, category, header_format)\n",
    "            for i, metric in enumerate(['mean', 'median', 'stdv', 'total']):\n",
    "                stats_sheet.write(1, col_idx+i, metric, header_format)\n",
    "            col_idx += 4\n",
    "        \n",
    "        # Histograms sheet\n",
    "        df_hists.to_excel(writer, sheet_name='Histograms', index=False)\n",
    "        hist_sheet = writer.sheets['Histograms']\n",
    "        \n",
    "        # Insert images\n",
    "        for idx, row in df_hists.iterrows():\n",
    "            img_data = BytesIO(row['Histogram'])\n",
    "            hist_sheet.insert_image(\n",
    "                idx + 1, 3,  # Start from row 1, column D\n",
    "                row['Filename'],\n",
    "                {'image_data': img_data, 'x_offset': 5, 'y_offset': 5}\n",
    "            )\n",
    "        \n",
    "        # Set column widths and row heights\n",
    "        hist_sheet.set_column('A:A', 10)   # Year\n",
    "        hist_sheet.set_column('B:B', 30)   # Filename\n",
    "        hist_sheet.set_column('C:C', 15)   # Category\n",
    "        hist_sheet.set_column('D:D', 60)   # Histogram\n",
    "        \n",
    "        for row in range(1, len(df_hists)+1):\n",
    "            hist_sheet.set_row(row, 100)\n",
    "\n",
    "        # Format numbers in statistics sheet\n",
    "        num_format = workbook.add_format({'num_format': '0.000'})\n",
    "        total_format = workbook.add_format({'num_format': '#,##0'})\n",
    "        for row in range(2, len(df_stats)+2):\n",
    "            for col in range(1, len(df_stats.columns)):\n",
    "                value = df_stats.iloc[row-2, col]\n",
    "                if pd.isna(value):\n",
    "                    stats_sheet.write_blank(row, col, None)\n",
    "                elif (col % 4) == 0:  # Total columns\n",
    "                    stats_sheet.write(row, col, value, total_format)\n",
    "                else:\n",
    "                    stats_sheet.write(row, col, value, num_format)\n",
    "        \n",
    "        stats_sheet.set_column(0, 0, 10)  # Year column\n",
    "        for col in range(1, len(df_stats.columns)):\n",
    "            stats_sheet.set_column(col, col, 15)\n",
    "\n",
    "    print(\"Analysis results saved to analysis_results.xlsx\")\n",
    "else:\n",
    "    print(\"No data processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2015\n",
      "Processing 2016\n",
      "Processing 2017\n",
      "Processing 2018\n",
      "Processing 2019\n",
      "Processing 2020\n",
      "Processing 2021\n",
      "Processing 2022\n",
      "Processing 2023\n",
      "Processing 2024\n",
      "Processing 2025\n",
      "Analysis results saved to analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "base_dir = 'historic_data'\n",
    "\n",
    "class RossROIManager:\n",
    "    def __init__(self):\n",
    "        self.rois = {\n",
    "            'iaw_ross': None,\n",
    "            'epw_ross': None\n",
    "        }\n",
    "        self.first_files_processed = {\n",
    "            'iaw_ross': False,\n",
    "            'epw_ross': False\n",
    "        }\n",
    "\n",
    "    def get_rois(self, category):\n",
    "        return self.rois[category]\n",
    "\n",
    "    def set_rois(self, category, rois):\n",
    "        self.rois[category] = rois\n",
    "        self.first_files_processed[category] = True\n",
    "\n",
    "    def needs_roi_selection(self, category):\n",
    "        return not self.first_files_processed[category]\n",
    "\n",
    "ross_manager = RossROIManager()\n",
    "\n",
    "def categorize_file(filename):\n",
    "    lower_name = filename.lower()\n",
    "    if 'iaw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'iaw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'iaw_ross'\n",
    "    elif 'epw' in lower_name:\n",
    "        if 'ccd' in lower_name:\n",
    "            return 'epw_ccd'\n",
    "        elif 'ross' in lower_name:\n",
    "            return 'epw_ross'\n",
    "    return 'other'\n",
    "\n",
    "class ROISelector:\n",
    "    def __init__(self, image, filename, year, category):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.image = image\n",
    "        self.filename = filename\n",
    "        self.year = year\n",
    "        self.category = category\n",
    "        self.rois = []\n",
    "        \n",
    "        self.ax.imshow(self.image, cmap='gray')\n",
    "        self.ax.set_title(f\"Select 2 ROIs for {category}\\n{filename} ({year})\")\n",
    "        \n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax, self.on_select,\n",
    "            useblit=True, button=[1],\n",
    "            minspanx=5, minspany=5,\n",
    "            spancoords='pixels', interactive=True\n",
    "        )\n",
    "        plt.show(block=True)\n",
    "\n",
    "    def on_select(self, eclick, erelease):\n",
    "        if len(self.rois) >= 2:\n",
    "            return\n",
    "        \n",
    "        x1 = int(min(eclick.xdata, erelease.xdata))\n",
    "        x2 = int(max(eclick.xdata, erelease.xdata))\n",
    "        y1 = int(min(eclick.ydata, erelease.ydata))\n",
    "        y2 = int(max(eclick.ydata, erelease.ydata))\n",
    "        self.rois.append((x1, y1, x2-x1, y2-y1))\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=1.5, edgecolor='red', facecolor='none')\n",
    "        self.ax.add_patch(rect)\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        if len(self.rois) == 2:\n",
    "            plt.close()\n",
    "\n",
    "def process_hdf4(file_path):\n",
    "    try:\n",
    "        hdf = SD(file_path, SDC.READ)\n",
    "        dataset = hdf.select('Streak_array')\n",
    "        data = dataset.get()\n",
    "        background = data[1, :, :]\n",
    "        hdf.end()\n",
    "        return background.astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_histogram(pixels, filename, year):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.hist(pixels, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.title(f\"Histogram\\n{filename} ({year})\")\n",
    "    plt.xlabel(\"Pixel Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    return buf.getvalue()\n",
    "\n",
    "def analyze_file(file_path, year, category):\n",
    "    background = process_hdf4(file_path)\n",
    "    if background is None:\n",
    "        return None, None\n",
    "\n",
    "    filename = os.path.basename(file_path)\n",
    "    histogram = None\n",
    "    \n",
    "    if 'ccd' in category:\n",
    "        # Use full frame for CCD categories\n",
    "        pixels = background.flatten()\n",
    "        histogram = generate_histogram(pixels, filename, year)\n",
    "        stats = {\n",
    "            'mean': np.mean(pixels),\n",
    "            'median': np.median(pixels),\n",
    "            'stdv': np.std(pixels),\n",
    "            'total': len(pixels)\n",
    "        }\n",
    "    else:\n",
    "        # Ross categories\n",
    "        if ross_manager.needs_roi_selection(category):\n",
    "            selector = ROISelector(background, filename, year, category)\n",
    "            ross_manager.set_rois(category, selector.rois)\n",
    "        \n",
    "        rois = ross_manager.get_rois(category)\n",
    "        pixels = []\n",
    "        for x, y, w, h in rois:\n",
    "            roi_data = background[y:y+h, x:x+w]\n",
    "            pixels.extend(roi_data.flatten())\n",
    "        \n",
    "        if pixels:\n",
    "            histogram = generate_histogram(pixels, filename, year)\n",
    "            stats = {\n",
    "                'mean': np.mean(pixels),\n",
    "                'median': np.median(pixels),\n",
    "                'stdv': np.std(pixels),\n",
    "                'total': len(pixels)\n",
    "            }\n",
    "        else:\n",
    "            stats = None\n",
    "\n",
    "    return stats, histogram\n",
    "\n",
    "def process_year(year):\n",
    "    year_dir = os.path.join(base_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        return None, []\n",
    "    \n",
    "    hdf_files = sorted([f for f in os.listdir(year_dir) if f.endswith('.hdf')])\n",
    "    year_stats = {'Year': year}\n",
    "    hist_data = []\n",
    "    \n",
    "    category_data = {\n",
    "        'iaw_ccd': [], 'iaw_ross': [],\n",
    "        'epw_ccd': [], 'epw_ross': []\n",
    "    }\n",
    "    \n",
    "    for file_name in hdf_files:\n",
    "        file_path = os.path.join(year_dir, file_name)\n",
    "        filename = os.path.basename(file_path)\n",
    "        category = categorize_file(filename)\n",
    "        \n",
    "        if category not in category_data:\n",
    "            continue\n",
    "            \n",
    "        stats, hist = analyze_file(file_path, year, category)\n",
    "        if stats and hist:\n",
    "            category_data[category].append(stats)\n",
    "            hist_data.append({\n",
    "                'Year': year,\n",
    "                'Filename': filename,\n",
    "                'Category': category.replace('_', ' '),\n",
    "                'Histogram': hist\n",
    "            })\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    for cat, entries in category_data.items():\n",
    "        prefix = cat.replace('_', ' ')\n",
    "        if entries:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.mean([e['mean'] for e in entries])\n",
    "            year_stats[f\"{prefix} - median\"] = np.mean([e['median'] for e in entries])\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.mean([e['stdv'] for e in entries])\n",
    "            year_stats[f\"{prefix} - total\"] = np.sum([e['total'] for e in entries])\n",
    "        else:\n",
    "            year_stats[f\"{prefix} - mean\"] = np.nan\n",
    "            year_stats[f\"{prefix} - median\"] = np.nan\n",
    "            year_stats[f\"{prefix} - stdv\"] = np.nan\n",
    "            year_stats[f\"{prefix} - total\"] = 0\n",
    "    \n",
    "    return year_stats, hist_data\n",
    "\n",
    "# Main processing\n",
    "all_data = []\n",
    "all_hists = []\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    print(f\"Processing {year}\")\n",
    "    year_stat, year_hists = process_year(year)\n",
    "    if year_stat:\n",
    "        all_data.append(year_stat)\n",
    "    if year_hists:\n",
    "        all_hists.extend(year_hists)\n",
    "\n",
    "# Create and save Excel report\n",
    "if all_data:\n",
    "    # Prepare statistics DataFrame\n",
    "    df_stats = pd.DataFrame(all_data)\n",
    "    categories = ['iaw ccd', 'iaw ross', 'epw ccd', 'epw ross']\n",
    "    column_order = ['Year'] + [\n",
    "        f\"{cat} - {metric}\" for cat in categories \n",
    "        for metric in ['mean', 'median', 'stdv', 'total']\n",
    "    ]\n",
    "    df_stats = df_stats.reindex(columns=column_order)\n",
    "    \n",
    "    # Prepare histograms DataFrame\n",
    "    df_hists = pd.DataFrame(all_hists)\n",
    "    \n",
    "    # Create Excel writer\n",
    "    with pd.ExcelWriter(\n",
    "        'analysis_results.xlsx',\n",
    "        engine='xlsxwriter',\n",
    "        engine_kwargs={'options': {'nan_inf_to_errors': True}}\n",
    "    ) as writer:\n",
    "        # Write statistics data starting at row 3 (Excel row 4)\n",
    "        df_stats.to_excel(writer, sheet_name='Statistics', index=False, startrow=3)\n",
    "        \n",
    "        workbook = writer.book\n",
    "        stats_sheet = writer.sheets['Statistics']\n",
    "        \n",
    "        # Create header format\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'align': 'center',\n",
    "            'valign': 'vcenter',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Write and merge headers\n",
    "        # Year header (Excel rows 1-2)\n",
    "        stats_sheet.merge_range('A1:A2', 'Year', header_format)\n",
    "        \n",
    "        # Category headers (Excel row 1)\n",
    "        col_idx = 1\n",
    "        for category in categories:\n",
    "            stats_sheet.merge_range(0, col_idx, 0, col_idx+3, category, header_format)\n",
    "            col_idx += 4\n",
    "        \n",
    "        # Metric subheaders (Excel row 2)\n",
    "        col_idx = 1\n",
    "        for _ in categories:\n",
    "            for metric in ['mean', 'median', 'stdv', 'total']:\n",
    "                stats_sheet.write(1, col_idx, metric, header_format)\n",
    "                col_idx += 1\n",
    "        \n",
    "        # Format data cells\n",
    "        num_format = workbook.add_format({'num_format': '0.000'})\n",
    "        total_format = workbook.add_format({'num_format': '#,##0'})\n",
    "        \n",
    "        for df_row in range(len(df_stats)):\n",
    "            excel_row = df_row + 3  # Data starts at Excel row 4\n",
    "            # Year column\n",
    "            stats_sheet.write(excel_row, 0, df_stats.iloc[df_row, 0])\n",
    "            \n",
    "            # Data columns\n",
    "            for col in range(1, len(df_stats.columns)):\n",
    "                value = df_stats.iloc[df_row, col]\n",
    "                if pd.isna(value):\n",
    "                    stats_sheet.write_blank(excel_row, col, None)\n",
    "                elif (col % 4) == 0:  # Total columns\n",
    "                    stats_sheet.write(excel_row, col, value, total_format)\n",
    "                else:\n",
    "                    stats_sheet.write(excel_row, col, value, num_format)\n",
    "        \n",
    "        # Set column widths\n",
    "        stats_sheet.set_column(0, 0, 10)  # Year column\n",
    "        for col in range(1, len(df_stats.columns)):\n",
    "            stats_sheet.set_column(col, col, 15)\n",
    "\n",
    "        # Histograms sheet\n",
    "        df_hists.to_excel(writer, sheet_name='Histograms', index=False)\n",
    "        hist_sheet = writer.sheets['Histograms']\n",
    "        \n",
    "        # Insert images\n",
    "        for idx, row in df_hists.iterrows():\n",
    "            img_data = BytesIO(row['Histogram'])\n",
    "            hist_sheet.insert_image(\n",
    "                idx + 1, 3,  # Start from row 1, column D\n",
    "                row['Filename'],\n",
    "                {'image_data': img_data, 'x_offset': 5, 'y_offset': 5}\n",
    "            )\n",
    "        \n",
    "        # Set column widths and row heights\n",
    "        hist_sheet.set_column('A:A', 10)   # Year\n",
    "        hist_sheet.set_column('B:B', 30)   # Filename\n",
    "        hist_sheet.set_column('C:C', 15)   # Category\n",
    "        hist_sheet.set_column('D:D', 60)   # Histogram\n",
    "        \n",
    "        for row in range(1, len(df_hists)+1):\n",
    "            hist_sheet.set_row(row, 100)\n",
    "\n",
    "    print(\"Analysis results saved to analysis_results.xlsx\")\n",
    "else:\n",
    "    print(\"No data processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsadar-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
